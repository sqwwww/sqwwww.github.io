{"pages":[{"title":"About","date":"2022-09-03T02:52:42.014Z","path":"about/index.html","text":""},{"title":"Categories","date":"2022-09-03T02:52:42.015Z","path":"categories/index.html","text":""},{"title":"Tags","date":"2022-09-03T02:52:42.016Z","path":"tags/index.html","text":""}],"posts":[{"title":"","date":"2022-09-03T02:52:42.023Z","path":"wiki/RNA流程/","text":"","tags":[],"categories":[]},{"title":"","date":"2022-09-03T02:52:42.019Z","path":"wiki/biosoft/gatk_snp流程/","text":"gatk_snp流程.md gatk官方博文，描述 gatk4和之前版本的差异 http://broad.io/GATK4-1一些terra上的实例：https://terra.bio/#library/showcase 数据预处理：map bam文件中会包含read group的信息，在之后的分析中要用到mark duplicatesrecalibrate base quality score（BQSR）：对machine error（包含pcr error和测序error）重新校准analysis-ready bam 多样本可以做joint calling 对每个样本单独call snp，得到 gvcf（包含基因组上所有位点的信息） 用所有样本的gvcf 做一个 joint calling，筛选出至少一个样本中存在变异的位点 建立索引nohup ~&#x2F;biosoft&#x2F;gatk-4.1.9.0&#x2F;gatk CreateSequenceDictionary -R subelongatus.fa -O gatk.dict &amp;&gt; gatkIndex.log &amp; gatk必须要sam&#x2F;bam文件的头文件信息（reads group），其中ID，PL和SM信息是必须要的若是忘记添加read group信息还以通过 AddOrReplaceReadGroups 添加GATK 要求read group的格式ID &#x3D; Read group identifier 每一个read group 独有的ID，每一对reads 均有一个独特的ID，可以自定义命名；PL &#x3D; Platform 测序平台；ILLUMINA, SOLID, LS454, HELICOS and PACBIO，不区分大小写；SM &#x3D; sample reads属于的样品名；SM要设定正确，因为GATK产生的VCF文件也使用这个名字;LB &#x3D; DNA preparation library identifier 对一个read group的reads进行重复序列标记时，需要使用LB来区分reads来自那条lane;有时候，同一个库可能在不同的lane上完成测序;为了加以区分， 同一个或不同库只要是在不同的lane产生的reads都要单独给一个ID. 一般无特殊说明，成对儿read属于同一库，可自定义，比如：library1 gatk AddOrReplaceReadGroups -I .bam -O .add.bam -LB library1 -PL illumina -PU pl1 -SM name byLongxin 123456789101112131415161718ref=Mhap1refFa=ref/$&#123;ref&#125;.fastasample=malesamtools faidx $refFagatk CreateSequenceDictionary -R=$refFa -O=ChrAsm.dictgatk MarkDuplicates -I=$sample.$ref.sorted.bam -O=$sample.$ref.dedup.bam -M=$sample.$ref.msamtools index $sample.$ref.dedup.bamgatk AddOrReplaceReadGroups -I=$sample.$ref.dedup.bam -O=$sample.$ref.dedup.bam.rg.bam RGID=4$sample RGLB=lib$sample RGPU=unit1 RGSM=$sample RGPL=illuminasamtools index $sample.$ref.dedup.bam.rg.bam#java -Xmx83g -jar GenomeAnalysisTK.jar -T HaplotypeCaller -R $refFa -I $sample.$ref.dedup.bam.rg.bam --emitRefConfidence GVCF -o $sample.$ref.dedup.bam.rg.bam.g.vcf.gz -nct 12gatk --java-options &quot;-Xmx83G&quot; HaplotypeCaller -R $refFa -I $sample.$ref.dedup.bam.rg.bam --emitRefConfidence GVCF -o $sample.$ref.dedup.bam.rg.bam.g.vcf.gz -nct 12","tags":[],"categories":[{"name":"biosoft","slug":"biosoft","permalink":"https://sqwwww.github.io/categories/biosoft/"}]},{"title":"","date":"2022-09-03T02:52:42.018Z","path":"wiki/biosoft/DNA比对流程/","text":"用来 call coverage 和 snp 的流程，从reads到结果图 ref&#x3D;ref&#x2F;bowtie2Index&#x2F;subthreads&#x3D;20cat fq_list|while read id; do arr=($id) fq1=$&#123;arr[0]&#125; fq2=$&#123;arr[1]&#125; sample=`basename $fq1 _1.fq.gz` echo $&#123;sample&#125;-------------------------- fastp -i $fq1\\ -I $fq2\\ -o fq/$&#123;sample&#125;_clean_1.fastq.gz \\ -O fq/$&#123;sample&#125;_clean_2.fastq.gz \\ --thread=$threads bowtie2 -p $&#123;threads&#125; \\ -x $&#123;ref&#125; \\ -1 fq/$&#123;sample&#125;_clean_1.fastq.gz \\ -2 fq/$&#123;sample&#125;_clean_2.fastq.gz \\ -S $&#123;sample&#125;.sam grep -P &#39;@|AS:&#39; $&#123;sample&#125;.sam | grep -v &quot;XS:i&quot; &gt; $&#123;sample&#125;.uniq.sam samtools view -@ 10 -bS $&#123;sample&#125;.uniq.sam | samtools sort -o $&#123;sample&#125;.uniq.bam samtools index $&#123;sample&#125;.uniq.bam done sexfindR的流程 call coverage 用到了 difcover，依赖到bioconductor-dnacopy，安装在 chipseq-py36下了 12(chipseq-py36) qianwei ~/project/seahorse/published/assembly/map$conda install -c bioconda bioconductor-dnacopy","tags":[],"categories":[{"name":"biosoft","slug":"biosoft","permalink":"https://sqwwww.github.io/categories/biosoft/"}]},{"title":"Hello World","date":"2022-09-03T02:52:42.017Z","path":"wiki/2/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[],"categories":[{"name":"2","slug":"2","permalink":"https://sqwwww.github.io/categories/2/"}]},{"title":"bwa","date":"2022-08-13T05:43:13.000Z","path":"wiki/bwa/","text":"bwa index [ –p prefix ] &lt;in.db.fasta&gt; bwa mem -t 25 $genome $read1 $read2 | samtools sort -@ 10 -m 3G -O BAM -o $genome.$sample.sorted.bam - samtools index $genome.$sample.sorted.bam 参考资料","tags":[],"categories":[]},{"title":"genoPlotR","date":"2022-08-12T08:17:54.000Z","path":"wiki/genoPlotR/","text":"genoPlotR是用来展示基因组结构的R包 基础的结构绘制 参考资料","tags":[],"categories":[]},{"title":"lipidDroplet","date":"2022-08-08T03:16:50.000Z","path":"wiki/lipidDroplet/","text":"lipid droplet biology lipid是什么最主要的能量储存形式以甘油三酯（最主要），兹醇酯，蜡酯等形式存储用作能量储存的优点：能量密度高；高度还原，可用于氧化；存储过程不需要水的参与 lipid droplet是什么是一种存储油脂的细胞器，磷脂单分子层外膜，中间包裹着中性的脂质核心，脂质核心中通常含有甘油三酯（最主要），兹醇酯，蜡酯等；磷脂单分子层外膜通常被蛋白修饰，这些蛋白一般会参加脂质的代谢过程 lipid droplet 与细胞质脂滴在细胞质中以小液滴的形式存在，形成乳浊液，连续相是胞浆，分散相是脂滴。 lipid droplet 在多细胞动物中的分布ubiquitous，在人中，几乎所有细胞都能合成脂滴；但是脂质的存储主要在脂肪组织（adipose tissue）中。 脂滴的分泌乳腺上皮细胞分泌牛奶（牛奶含有大量脂肪），就存在大量的脂滴分泌过程 脂滴的合成脂滴合成通路 合成甘油三酯: DGAT（ER表面），合成的甘油三酯被输送到ER的磷脂双分子层中间的空腔 脂滴在ER上合成的起始阶段: seipin（ER表面）,LPAF1(ER表面，脂滴表面)，合成的甘油三酯在ER特定位置堆积，靠近胞质的磷脂层隆起，出芽，直至脂滴与内质网分离，LPAF1在这一过程中也从内质网表面进入到脂滴表面。 脂滴与ER分离，并招募表面蛋白：两种途径，从细胞质中招募；从内质网上招募（GPAT4） 脂滴进一步生长成熟 perlin 蛋白： 合成于游离核糖体 mammal中含有5种perilipin蛋白，Perilipins 2 and 3在所有组织中都表达，145具有组织特异性。teleost中含有4种perilipin蛋白，其中perilipin6是teleost特有的。皮肤黄色素细胞（xanthophores）中含有包裹类胡萝卜素的脂滴，perilipin6就集中在这一类脂滴上，促进相关色素的聚集和浓度提高，与鱼的体色相关。哺乳动物中包裹视黄醇（维生素A，可以由胡萝卜素转变而成）的脂滴表面富集perilipin2和3。 鱼类具备6种起源于神经嵴（Neural crest）的色素细胞，分别为黑色素细胞（Melanophores）、黄色素细胞（Xanthophores）、红色素细胞（Erythrophores）、彩虹细胞（Iridophores），白色素细胞（Leucophores）和蓝色素细胞（Cyanophores）。哺乳类和鸟类仅含有1种神经嵴起源的色素细胞类型，即黑素细胞（Melanocytes）。鱼类色素细胞主要存在于表皮的真皮中，其中黑色素细胞、黄色素细胞、红色素细胞和蓝色素细胞含有相应的色素物质。 所有硬骨鱼类的色素细胞均起源于胚胎时期外胚层的神经嵴细胞群，由一小组神经嵴细胞群首先形成色素母细胞（Chromatoblasts），随着发育的进行，再分化为黑色素细胞、黄色素细胞和彩虹色素细胞等其他色素细胞，在色素细胞到达一定的数量，开始色素模式的形成，也就是我们看到的成体鱼类所具有的典型的条纹和色素斑点。 plin6在斑马鱼的胚胎发育时期可以检测到表达，在成年个体的皮肤上高表达 正常情况下，未磷酸化的perilipin蛋白包裹在脂滴表面，阻碍脂质降解蛋白接触到脂滴内的脂质，从而使脂滴的的脂质可以存储下来；当perilipin蛋白处于激发态的时候（被PKA磷酸化），HSL（脂肪酶）与磷酸化的perilipin共定位于脂滴表面，HSL更容易接触到脂滴内的脂质，从而发挥脂解作用。 HSL是水解甘油三酯的脂肪酶，非活化状态的HSL存在于细胞质中 脂质如何通过胎盘 正常情况下脂质很难通过胎盘，甘油三脂不能通过扩散进入细胞，但可以以两种方式进入胎盘，为胎儿提供营养 1. 脂质与蛋白结合形成脂蛋白，胎盘上有脂蛋白的受体，可以把脂蛋白转运进胎盘。 2. 脂肪酸可以通过自由扩散进入胎盘，这就需要母体有比较高的脂肪酸浓度。 特殊情况：乳腺上皮可以分泌脂滴 lipoprotein脂蛋白和lipid droplet脂滴是一个东西吗 不是，二者结构上比较相似，都是由中性脂质内核和磷脂单分子外膜构成，外膜上存在蛋白。但是不同点如下：大小不同，脂滴（100nm - 100 um）比脂蛋白（20-500 nm）要大很多；功能不同，脂滴主要用做细胞内脂质的储存，脂蛋白主要用作脂质在血液中的运输，因此二者表面的蛋白种类差异也很大。几乎所有的细胞都能合成脂滴，但只有少部分的细胞类型可以合成脂蛋白组装需要的特殊蛋白（比如载脂蛋白apoB，apolipoprotein B 和microsomal TG transfer protein） 参考资料","tags":[],"categories":[]},{"title":"blast","date":"2022-08-07T10:12:35.000Z","path":"wiki/blast/","text":"pep_fa&#x3D;Habd.faamakeblastdb -in $pep_fa -dbtype prot -out blastIndex&#x2F;Ha_pep blastp -query $qry_fa -out $out_name -db $index -outfmt 6 -evalue 1e-5 -num_threads 11 -max_target_seqs 6 tblastn -query $qry_fa -out $out_name -db $index -outfmt 6 -evalue 1e-5 -num_threads 11 -max_target_seqs 1blastp输出结果 qseqid query (e.g., unknown gene) sequence id sseqid subject (e.g., reference genome) sequence id pident percentage of identical matches length alignment length (sequence overlap) mismatch number of mismatches gapopen number of gap openings qstart start of alignment in query qend end of alignment in query sstart start of alignment in subject send end of alignment in subject evalue expect value bitscore bit score blast 参数详细如果只想取query的最优比对，设置 -max_target_seqs 1；自我比对的时候只会得到原始序列想要每个query-subject的唯一最优对应，设置 -max_target_seqs 500 -max_hsps 1 blastdbcmd 从blast构建好的数据库中提取序列 blatref_fa&#x3D;qry_fa&#x3D;out_name&#x3D;blat -t&#x3D;dna -q&#x3D;dna $ref_fa $qry_fa $out_name nucmer nucmer -p $1_$2 $ref $querynucmer fhap1_chr1.fa fhap2_chr1.fa &amp;&gt; fhap12.log&#x2F;public&#x2F;home&#x2F;Zexian&#x2F;mummer3&#x2F;MUMmer3.23&#x2F;delta-filter -1 out.delta &gt; filter.delta &#x2F;public&#x2F;home&#x2F;Zexian&#x2F;mummer3&#x2F;MUMmer3.23&#x2F;show-coords -T -q -H filter.delta &gt; XR_coord.txt 参考资料","tags":[],"categories":[]},{"title":"fish","date":"2022-08-05T08:30:12.000Z","path":"wiki/fish/","text":"脊椎动物亚门vertebrate 圆口纲 软骨鱼纲 硬骨鱼纲 两栖纲 爬行纲 鸟纲 哺乳纲 参考资料","tags":[],"categories":[]},{"title":"fastq-dump","date":"2022-07-30T15:54:51.000Z","path":"wiki/fastq-dump/","text":"fastq-dump –gzip –split-3 SRR12601728.sra，用了两个小时，真慢–split-3智能检测是单端还是双端的readsfastqc查看是否为clean reads 参考资料","tags":[],"categories":[]},{"title":"coverage_pipeline","date":"2022-07-28T09:45:49.000Z","path":"wiki/coverage-pipeline/","text":"从bam文件到coveragesambamba depth window –overlap 2500 -w 5000 -o female_Mhap1_depth.txt -t 28 -q&#x3D;30 $bam 得到用来做normalise的depth 12345file=$1samtools stats $file &gt; $&#123;file&#125;_tempnumber=$(grep ^COV $&#123;file&#125;_temp | cut -f 2- | awk -v max=0 &#x27;&#123;if($3&gt;max)&#123;want=$2; max=$3&#125;&#125;END&#123;print want&#125; &#x27; -)rm $&#123;file&#125;_tempecho $file $number &gt; $&#123;file&#125;_modal_depth.txt 参考资料","tags":[],"categories":[]},{"title":"R","date":"2022-07-25T04:40:17.000Z","path":"wiki/R/","text":"data.table 赋值 df_combined[,’:&#x3D;’(‘1_2’ &#x3D; sub1 &gt; sub2, ‘1_3’ &#x3D; sub1 &gt; sub3, ‘1_4’ &#x3D; sub1 &gt; sub4, ‘1_5’ &#x3D; sub1&gt; sub5, ‘2_3’ &#x3D; sub2&gt;sub3, ‘2_4’&#x3D; sub2&gt;sub4,’2_5’&#x3D; sub2&gt;sub5, ‘3_4’&#x3D;sub3&gt;sub4, ‘3_5’&#x3D;sub3&gt;sub5, ‘4_5’&#x3D;sub4&gt;sub5)] DT[i, c(“LHS1”, “LHS2”) :&#x3D; list(RHS1, RHS2), by &#x3D; …] window变region myWindow[order(CN, S,E), g := .(cumsum(c(0L,(shift(S, -1) &gt; cummax(E))[-.N]))),by = CN] myRegion &lt;- myWindow[order(CN,S,E),.(NS = min(S), NE = max(E), num = .N, log = mean(log2MFR)), by = .(CN, g)] df_combined_filtered[order(CHROM, BIN_START,BIN_END), g := .(cumsum(c(0L,(shift(BIN_START, -1) &gt; cummax(BIN_END))[-.N]))),by = CHROM] myRegion &lt;- df_combined_filtered[order(CHROM, BIN_START,BIN_END),.(NS = min(S), NE = max(E), num = .N, by = .(CHROM, g)] 根据向量选取列（select multiple columns using a character vector） 1234columns &lt;- c(&#x27;mpg&#x27;, &#x27;cyl&#x27;, &#x27;disp&#x27;)mtcars_dt[, columns, with=FALSE]mtcars_dt[, .(mpg, cyl, gear)] 对某一列重命名 setnames(tmp_data, &quot;gene_id&quot;, current_sampleID) Pitching[ , .SD, .SDcols = c(&#39;W&#39;, &#39;L&#39;, &#39;G&#39;)] DT[i, c(&quot;LHS1&quot;, &quot;LHS2&quot;) := list(RHS1, RHS2), by = ...] 填补NA replace_na(df$X1,5) # 把df的X1列中的NA填充为5 改变列的数据类型 mRNA_gff[, V3:= lapply(V3, as.numeric)] setkey和setkeyv 用来对data table 进行排序，setkey是根据一列排，setkeyv可以根据多列排 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465 a &lt;- fread(file = paste0(&quot;../published/NC21/&quot;,samp,&quot;_depth.txt&quot;)) setnames(a, &quot;# chrom&quot;, &quot;chrom&quot;) setnames(a, &quot;meanCoverage&quot;, &quot;samp&quot;) tmp_1 &lt;- a[,.(chrom,chromStart,chromEnd, samp)] setkeyv(tmp_1, c(&quot;chrom&quot;,&quot;chromStart&quot;,&quot;chromEnd&quot;))dylyrfilterraw_ortho %&gt;% filter_all(all_vars(. != &quot;N&quot;))msleep %&gt;% select(name, sleep_total) %&gt;% filter(between(sleep_total, 16, 18))msleep %&gt;% select(name, sleep_total) %&gt;% filter(near(sleep_total, 17, tol = sd(sleep_total)))msleep %&gt;% select(order, name, sleep_total) %&gt;% filter(order %in% c(&quot;Didelphimorphia&quot;, &quot;Diprotodontia&quot;))msleep %&gt;% select(order, name, sleep_total) %&gt;% filter(!order %in% remove)msleep %&gt;% select(name, sleep_total) %&gt;% filter(str_detect(tolower(name), pattern = &quot;mouse&quot;)) #filter(grepl(pattern=&quot;mouse&quot;, tolower(name)))filter(condition1, condition2)filter(condition1, !condition2)filter(condition1 | condition2) # return rows where condition 1 and/or condition 2 is met.filter(xor(condition1, condition2) # return all rows where only one of the conditions is met, and not when both conditions are met.# 删除某一列含有NA的行msleep %&gt;% select(name, conservation:sleep_cycle) %&gt;% filter(!is.na(conservation))#根据多列进行过滤 filter_all() will filter all columns based on your further instructions filter_if() requires a function that returns a boolean to indicate which columns to filter on. If that is true, the filter instructions will be followed for those columns. filter_at() requires you to specify columns inside a vars() argument for which the filtering will be done. any_vars() statement is equivalent to OR all_vars() statement is equivalent to AND msleep %&gt;% select(name:order, sleep_total, -vore) %&gt;% filter_all(any_vars(str_detect(., pattern = &quot;Ca&quot;))) msleep %&gt;% select(name, sleep_total:bodywt) %&gt;% filter_all(any_vars(. &lt; 0.1)) msleep %&gt;% select(name:order, sleep_total:sleep_rem) %&gt;% filter_if(is.character, any_vars(is.na(.))) # is.numeric, is.integer, is.double, is.logical, is.factor msleep %&gt;% select(name, sleep_total:sleep_rem, brainwt:bodywt) %&gt;% filter_at(vars(sleep_total, sleep_rem), all_vars(.&gt;5)) #all_vars() if all columns need to return TRUE (AND equivalent) # you can just select columns to which the change should happen via the vars() msleep %&gt;% select(name, sleep_total:sleep_rem, brainwt:bodywt) %&gt;% filter_at(vars(contains(&quot;sleep&quot;)), all_vars(.&gt;5)) #any_vars() in case just one variable needs to return TRUE (OR equivalent) 参考资料","tags":[],"categories":[]},{"title":"data.table用法","date":"2022-07-25T04:40:17.000Z","path":"wiki/shell技巧/","text":"加法 1234i=0let &#x27;i+=1&#x27;echo &#x27;scale=2;2+3&#x27; | bc if 语句 123if [-e filename]for 语句 12 关联数组 123456789101112131415161718192021declare -A ass_array # 声明ass_array=([&quot;PE&quot;]=0 [&quot;PM&quot;]=0 [&quot;PL&quot;]=0 [&quot;PN&quot;]=0 [&quot;PB&quot;]=0) # 初始化cat ../../published/mbe_15/phenotype.txt |while read id; do srr=`echo $id|awk &#x27;&#123;print $1&#125;&#x27;`pheno=`echo $id|awk &#x27;&#123;print $NF&#125;&#x27;`fq1=/public2/home/qianwei/project/seahorse/published/mbe_15/$srr/$&#123;srr&#125;_1.fastq.gzfq2=/public2/home/qianwei/project/seahorse/published/mbe_15/$srr/$&#123;srr&#125;_2.fastq.gzlet &#x27;ass_array[$pheno]+=1&#x27; # 赋值 加法#echo $pheno $&#123;ass_array[$pheno]&#125;fq11=Ha$&#123;pheno&#125;_MPL$&#123;ass_array[$pheno]&#125;_raw_1.fastq.gzfq22=Ha$&#123;pheno&#125;_MPL$&#123;ass_array[$pheno]&#125;_raw_2.fastq.gz#echo $fq11ln -s $fq1 $fq11ln -s $fq2 $fq22done cp 123456#从软链接拷贝软链接（默认拷贝文件）,用-d选项ln -s $source link_filecp -d link_file $new_dir# 从文件拷贝软链接，用 -s 选项cp -s $source link_file find,xargs 123456# 按时间查找, find . &#123;-atime/-ctime/-mtime/-amin/-cmin/-mmin&#125; [-/+]num-1 一天内+1 一天前# 按名称查找 -name 参数# xargs传递参数，-i选项，可以把参数传递给&#123;&#125;find ../final_fq -mtime -1 -name &quot;Ha*&quot; | xargs -i cp -d &#123;&#125; ./ 参考资料","tags":[],"categories":[]},{"title":"ragtag使用","date":"2022-07-18T15:54:44.000Z","path":"wiki/ragtag使用/","text":"ragtag.py scaffold &lt;reference.fa&gt; &lt;query.fa&gt; scaffolding options: -e &lt;exclude.txt&gt; list of reference sequences to ignore [null] -j &lt;skip.txt&gt; list of query sequences to leave unplaced [null] -J &lt;hard-skip.txt&gt; list of query headers to leave unplaced and exclude from ‘chr0’ (‘-C’) [null] -f INT minimum unique alignment length [1000] –remove-small remove unique alignments shorter than ‘-f’ -q INT minimum mapq (NA for Nucmer alignments) [10] -d INT maximum alignment merge distance [100000] -i FLOAT minimum grouping confidence score [0.2] -a FLOAT minimum location confidence score [0.0] -s FLOAT minimum orientation confidence score [0.0] -C concatenate unplaced contigs and make ‘chr0’ -r infer gap sizes. if not, all gaps are 100 bp -g INT minimum inferred gap size [100] -m INT maximum inferred gap size [100000] input&#x2F;output options: -o PATH output directory [.&#x2F;ragtag_output] -w overwrite intermediate files -u add suffix to unplaced sequence headers mapping options: -t INT number of minimap2&#x2F;unimap threads [1] –aligner PATH aligner executable (‘nucmer’, ‘unimap’ or ‘minimap2’) [minimap2] –mm2-params STR space delimited minimap2 parameters (overrides ‘-t’) [‘-x asm5’] –unimap-params STR space delimited unimap parameters (overrides ‘-t’) [‘-x asm5’] –nucmer-params STR space delimted nucmer parameters [‘–maxmatch -l 100 -c 500’] -C会将没地方放的contig&#x2F;scaffold连在一起放到chr0中（中间用100个N连接） ragtag.py scaffold -u $ref $query -t 20 -C cd ~&#x2F;project&#x2F;seahorse&#x2F;published&#x2F;assembly&#x2F;ragtagbash ragtag.sh &amp;&gt; He_log cd ~&#x2F;project&#x2F;seahorse&#x2F;published&#x2F;assembly&#x2F;map&#x2F;refln -s &#x2F;public2&#x2F;home&#x2F;qianwei&#x2F;project&#x2F;seahorse&#x2F;published&#x2F;assembly&#x2F;ragtag&#x2F;ragtag_output_He&#x2F;ragtag.scaffold.fasta subelongatus.fabash bowtie2Index.sh &amp;&gt; sub_build.logcd ..bash DNApipeline.sh &amp;&gt; sub.map.log 参考资料","tags":[],"categories":[]},{"title":"bowtieAndBowtie2","date":"2022-07-16T09:01:36.000Z","path":"wiki/biosoft/bowtieAndBowtie2/","text":"bowtie和bowtie2的区别这两个软件都适合DNA的比对，bowtie开发的比较早，适合短reads（50bp）的比对，bowtie2适合长一点的reads（150bp）的比对，现在的数据基本上都适合用bowtie2 bowtie2 如何选择 uniq mapping 的 reads 1grep &quot;AS:&quot; aligned.sam | grep -v &quot;XS:i&quot; hisat比的话 grep “NH:i:1” aligned.sam | grep -v “ZS:i” bowtie2 建立索引 1bowtie2-build --threads 25 $fa bowtie2Index/Ha bowtie2 比对 12345678910111213141516ref=~/project/brain/ref/bowtie2-index/dmel-r6.12cores=12cat clean_list|while read id; do arr=($id) fq1=$&#123;arr[0]&#125; fq2=$&#123;arr[1]&#125; prefix=`basename $fq1 _clean_R1.fq.gz` echo $&#123;prefix&#125;-------------------------------------------------------------------------------- bowtie2 -p $&#123;cores&#125; \\ -x $&#123;ref&#125; \\ -1 $&#123;fq1&#125; \\ -2 $&#123;fq2&#125; \\ -S $&#123;prefix&#125;.sam done $bowtie2-build -hBowtie 2 version 2.3.5.1 by Ben Langmead (&#x6c;&#97;&#x6e;&#x67;&#109;&#101;&#x61;&#64;&#99;&#115;&#x2e;&#x6a;&#104;&#x75;&#46;&#101;&#100;&#117;, www.cs.jhu.edu/~langmea)Usage: bowtie2-build [options]* reference_in comma-separated list of files with ref sequences bt2_index_base write bt2 data to files with this dir&#x2F;basename*** Bowtie 2 indexes work only with v2 (not v1). Likewise for v1 indexes. ***Options: -f reference files are Fasta (default) -c reference sequences given on cmd line (as ) –large-index force generated index to be ‘large’, even if ref has fewer than 4 billion nucleotides –debug use the debug binary; slower, assertions enabled –sanitized use sanitized binary; slower, uses ASan and&#x2F;or UBSan –verbose log the issued command -a&#x2F;–noauto disable automatic -p&#x2F;–bmax&#x2F;–dcv memory-fitting -p&#x2F;–packed use packed strings internally; slower, less memory –bmax max bucket sz for blockwise suffix-array builder –bmaxdivn max bucket sz as divisor of ref len (default: 4) –dcv diff-cover period for blockwise (default: 1024) –nodc disable diff-cover (algorithm becomes quadratic) -r&#x2F;–noref don’t build .3&#x2F;.4 index files -3&#x2F;–justref just build .3&#x2F;.4 index files -o&#x2F;–offrate SA is sampled every 2^ BWT chars (default: 5) -t&#x2F;–ftabchars # of chars consumed in initial lookup (default: 10) –threads # of threads –seed seed for random number generator -q&#x2F;–quiet verbose output (for debugging) -h&#x2F;–help print detailed description of tool and its options –usage print this usage message –version print version information and quit $bowtie2 -hBowtie 2 version 2.3.5.1 by Ben Langmead (&#108;&#97;&#x6e;&#x67;&#109;&#x65;&#97;&#64;&#x63;&#115;&#46;&#106;&#x68;&#117;&#46;&#101;&#100;&#x75;, www.cs.jhu.edu/~langmea)Usage: bowtie2 [options]* -x {-1 -2 | -U | –interleaved | -b } [-S ] Index filename prefix (minus trailing .X.bt2). NOTE: Bowtie 1 and Bowtie 2 indexes are not compatible. Files with #1 mates, paired with files in . Could be gzip’ed (extension: .gz) or bzip2’ed (extension: .bz2). Files with #2 mates, paired with files in . Could be gzip’ed (extension: .gz) or bzip2’ed (extension: .bz2). Files with unpaired reads. Could be gzip’ed (extension: .gz) or bzip2’ed (extension: .bz2). Files with interleaved paired-end FASTQ&#x2F;FASTA reads Could be gzip’ed (extension: .gz) or bzip2’ed (extension: .bz2). Files are unaligned BAM sorted by read name. File for SAM output (default: stdout) 参考资料","tags":[],"categories":[{"name":"biosoft","slug":"biosoft","permalink":"https://sqwwww.github.io/categories/biosoft/"}]},{"title":"StardewValley","date":"2022-07-16T07:54:51.000Z","path":"wiki/StardewValley/","text":"小桶和罐头瓶 参考资料","tags":[],"categories":[]},{"title":"stringtie使用","date":"2022-07-16T02:40:55.000Z","path":"wiki/stringtie使用/","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869$stringtie -hStringTie v2.1.5 usage:stringtie &lt;in.bam ..&gt; [-G &lt;guide_gff&gt;] [-l &lt;prefix&gt;] [-o &lt;out.gtf&gt;] [-p &lt;cpus&gt;] [-v] [-a &lt;min_anchor_len&gt;] [-m &lt;min_len&gt;] [-j &lt;min_anchor_cov&gt;] [-f &lt;min_iso&gt;] [-c &lt;min_bundle_cov&gt;] [-g &lt;bdist&gt;] [-u] [-L] [-e] [--viral] [-E &lt;err_margin&gt;] [--ptf &lt;f_tab&gt;] [-x &lt;seqid,..&gt;] [-A &lt;gene_abund.out&gt;] [-h] &#123;-B|-b &lt;dir_path&gt;&#125;Assemble RNA-Seq alignments into potential transcripts.Options: --version : print just the version at stdout and exit --conservative : conservative transcript assembly, same as -t -c 1.5 -f 0.05 --rf : assume stranded library fr-firststrand --fr : assume stranded library fr-secondstrand -G reference annotation to use for guiding the assembly process (GTF/GFF3) --ptf : load point-features from a given 4 column feature file &lt;f_tab&gt; -o output path/file name for the assembled transcripts GTF (default: stdout) -l name prefix for output transcripts (default: STRG) -f minimum isoform fraction (default: 0.01) -L long reads processing; also enforces -s 1.5 -g 0 (default:false) -R if long reads are provided, just clean and collapse the reads but do not assemble -m minimum assembled transcript length (default: 200) -a minimum anchor length for junctions (default: 10) -j minimum junction coverage (default: 1) -t disable trimming of predicted transcripts based on coverage (default: coverage trimming is enabled) -c minimum reads per bp coverage to consider for multi-exon transcript (default: 1) -s minimum reads per bp coverage to consider for single-exon transcript (default: 4.75) -v verbose (log bundle processing details) -g maximum gap allowed between read mappings (default: 50) -M fraction of bundle allowed to be covered by multi-hit reads (default:1) -p number of threads (CPUs) to use (default: 1) -A gene abundance estimation output file -E define window around possibly erroneous splice sites from long reads to look out for correct splice sites (default: 25) -B enable output of Ballgown table files which will be created in the same directory as the output GTF (requires -G, -o recommended) -b enable output of Ballgown table files but these files will be created under the directory path given as &lt;dir_path&gt; -e only estimate the abundance of given reference transcripts (requires -G) --viral : only relevant for long reads from viral data where splice sites do not follow consensus (default:false) -x do not assemble any transcripts on the given reference sequence(s) -u no multi-mapping correction (default: correction enabled) -h print this usage message and exitTranscript merge usage mode: stringtie --merge [Options] &#123; gtf_list | strg1.gtf ...&#125;With this option StringTie will assemble transcripts from multipleinput files generating a unified non-redundant set of isoforms. In this modethe following options are available: -G &lt;guide_gff&gt; reference annotation to include in the merging (GTF/GFF3) -o &lt;out_gtf&gt; output file name for the merged transcripts GTF (default: stdout) -m &lt;min_len&gt; minimum input transcript length to include in the merge (default: 50) -c &lt;min_cov&gt; minimum input transcript coverage to include in the merge (default: 0) -F &lt;min_fpkm&gt; minimum input transcript FPKM to include in the merge (default: 1.0) -T &lt;min_tpm&gt; minimum input transcript TPM to include in the merge (default: 1.0) -f &lt;min_iso&gt; minimum isoform fraction (default: 0.01) -g &lt;gap_len&gt; gap between transcripts to merge together (default: 250) -i keep merged transcripts with retained introns; by default these are not kept unless there is strong evidence for them -l &lt;label&gt; name prefix for output transcripts (default: MSTRG) The generic command line for the default usage has this format:: 1stringtie [-o &lt;output.gtf&gt;] [other_options] &lt;read_alignments.bam&gt; StringTie takes as input a SAM, BAM or CRAM file sorted by coordinate (genomic location).samtools sort -o alnst.sorted.bam alns.sam A reference annotation file in GTF or GFF3 format can be provided to StringTie using the -G option which can be used as ‘guides’ for the assembly process and help improve the transcript structure recovery for those transcripts. Expression estimation mode (-e),我该用这个模式，只做定量When the -e option is used, the reference annotation file -G is a required input and StringTie will not attempt to assemble the input read alignments but instead it will only estimate the expression levels of the “reference” transcripts provided in the -G file. With this option, no “novel” transcript assemblies (isoforms) will be produced, and read alignments not overlapping any of the given reference transcripts will be ignored, which may provide a considerable speed boost when the given set of reference transcripts is limited to a set of target genes for example. for each RNA-Seq sample, map the reads to the genome with HISAT2 using the –dta option. It is highly recommended to use the reference annotation information when mapping the reads, which can be either embedded in the genome index (built with the –ss and –exon options, see HISAT2 manual), or provided separately at run time (using the –known-splicesite-infile option of HISAT2). The SAM output of each HISAT2 run must be sorted and converted to BAM using samtools as explained above. 参考网页 ：http://ccb.jhu.edu/software/stringtie/index.shtml?t=manual hisat2_index&#x3D;&#x2F;public2&#x2F;home&#x2F;qianwei&#x2F;project&#x2F;seahorse&#x2F;02.ref&#x2F;hisat2Index&#x2F;Hagff&#x3D;&#x2F;public2&#x2F;home&#x2F;qianwei&#x2F;project&#x2F;seahorse&#x2F;02.ref&#x2F;Ha.gffthreads&#x3D;15cat fq.list| while read id; doarr&#x3D;($id)fq1&#x3D;${arr[0]}fq2&#x3D;${arr[1]} hisat2 -p $threads –dta -x $hisat2_index -1 $fq1 -2 $fq2 -S ${sample}.samgrep -P ‘@|NH:i:1\\b’ ${sample}.sam | grep -v “ZS:i” &gt; ${sample}.uniq.samsamtools view -@ 4 -bS ${sample}.uniq.sam | samtools sort -@ 4 -m 3g -o ${sample}.uniq.bam -stringtie -p $threads -G ${gff} -B -e -l ${sample} -o ${sample}.gtf ${sample}.uniq.bam HISAT2 version 2.2.1 by Daehwan Kim (&#x69;&#x6e;&#x66;&#112;&#104;&#105;&#x6c;&#x6f;&#64;&#x67;&#x6d;&#97;&#x69;&#108;&#x2e;&#99;&#x6f;&#x6d;, www.ccb.jhu.edu/people/infphilo)Usage: hisat2 [options]* -x {-1 -2 | -U } [-S ] Index filename prefix (minus trailing .X.ht2). Files with #1 mates, paired with files in . Could be gzip’ed (extension: .gz) or bzip2’ed (extension: .bz2). Files with #2 mates, paired with files in . Could be gzip’ed (extension: .gz) or bzip2’ed (extension: .bz2). Files with unpaired reads. Could be gzip’ed (extension: .gz) or bzip2’ed (extension: .bz2). File for SAM output (default: stdout) , , can be comma-separated lists (no whitespace) and can be specified many times. E.g. ‘-U file1.fq,file2.fq -U file3.fq’. Options (defaults in parentheses): Input: -q query input files are FASTQ .fq&#x2F;.fastq (default) –qseq query input files are in Illumina’s qseq format -f query input files are (multi-)FASTA .fa&#x2F;.mfa -r query input files are raw one-sequence-per-line -c , , are sequences themselves, not files -s&#x2F;–skip skip the first reads&#x2F;pairs in the input (none) -u&#x2F;–upto stop after first reads&#x2F;pairs (no limit) -5&#x2F;–trim5 trim bases from 5’&#x2F;left end of reads (0) -3&#x2F;–trim3 trim bases from 3’&#x2F;right end of reads (0) –phred33 qualities are Phred+33 (default) –phred64 qualities are Phred+64 –int-quals qualities encoded as space-delimited integers Presets: Same as: –fast –no-repeat-index –sensitive –bowtie2-dp 1 -k 30 –score-min L,0,-0.5 –very-sensitive –bowtie2-dp 2 -k 50 –score-min L,0,-1 Alignment: –bowtie2-dp use Bowtie2’s dynamic programming alignment algorithm (0) - 0: no dynamic programming, 1: conditional dynamic programming, and 2: unconditional dynamic programming (slowest) –n-ceil func for max # non-A&#x2F;C&#x2F;G&#x2F;Ts permitted in aln (L,0,0.15) –ignore-quals treat all quality values as 30 on Phred scale (off) –nofw do not align forward (original) version of read (off) –norc do not align reverse-complement version of read (off) –no-repeat-index do not use repeat index Spliced Alignment: –pen-cansplice penalty for a canonical splice site (0) –pen-noncansplice penalty for a non-canonical splice site (12) –pen-canintronlen penalty for long introns (G,-8,1) with canonical splice sites –pen-noncanintronlen penalty for long introns (G,-8,1) with noncanonical splice sites –min-intronlen minimum intron length (20) –max-intronlen maximum intron length (500000) –known-splicesite-infile provide a list of known splice sites –novel-splicesite-outfile report a list of splice sites –novel-splicesite-infile provide a list of novel splice sites –no-temp-splicesite disable the use of splice sites found –no-spliced-alignment disable spliced alignment –rna-strandness specify strand-specific information (unstranded) –tmo reports only those alignments within known transcriptome –dta reports alignments tailored for transcript assemblers –dta-cufflinks reports alignments tailored specifically for cufflinks –avoid-pseudogene tries to avoid aligning reads to pseudogenes (experimental option) –no-templatelen-adjustment disables template length adjustment for RNA-seq reads Scoring: –mp , max and min penalties for mismatch; lower qual &#x3D; lower penalty &lt;6,2&gt; –sp , max and min penalties for soft-clipping; lower qual &#x3D; lower penalty &lt;2,1&gt; –no-softclip no soft-clipping –np penalty for non-A&#x2F;C&#x2F;G&#x2F;Ts in read&#x2F;ref (1) –rdg , read gap open, extend penalties (5,3) –rfg , reference gap open, extend penalties (5,3) –score-min min acceptable alignment score w&#x2F;r&#x2F;t read length (L,0.0,-0.2) Reporting: -k It searches for at most distinct, primary alignments for each read. Primary alignments mean alignments whose alignment score is equal to or higher than any other alignments. The search terminates when it cannot find more distinct valid alignments, or when it finds , whichever happens first. The alignment score for a paired-end alignment equals the sum of the alignment scores of the individual mates. Each reported read or pair alignment beyond the first has the SAM ‘secondary’ bit (which equals 256) set in its FLAGS field. For reads that have more than distinct, valid alignments, hisat2 does not guarantee that the alignments reported are the best possible in terms of alignment score. Default: 5 (linear index) or 10 (graph index). Note: HISAT2 is not designed with large values for -k in mind, and when aligning reads to long, repetitive genomes, large -k could make alignment much slower. –max-seeds HISAT2, like other aligners, uses seed-and-extend approaches. HISAT2 tries to extend seeds to full-length alignments. In HISAT2, –max-seeds is used to control the maximum number of seeds that will be extended. For DNA-read alignment (–no-spliced-alignment), HISAT2 extends up to these many seeds and skips the rest of the seeds. For RNA-read alignment, HISAT2 skips extending seeds and reports no alignments if the number of seeds is larger than the number specified with the option, to be compatible with previous versions of HISAT2. Large values for –max-seeds may improve alignment sensitivity, but HISAT2 is not designed with large values for –max-seeds in mind, and when aligning reads to long, repetitive genomes, large –max-seeds could make alignment much slower. The default value is the maximum of 5 and the value that comes with -k times 2. -a&#x2F;–all HISAT2 reports all alignments it can find. Using the option is equivalent to using both –max-seeds and -k with the maximum value that a 64-bit signed integer can represent (9,223,372,036,854,775,807). –repeat report alignments to repeat sequences directly Paired-end: -I&#x2F;–minins minimum fragment length (0), only valid with –no-spliced-alignment -X&#x2F;–maxins maximum fragment length (500), only valid with –no-spliced-alignment –fr&#x2F;–rf&#x2F;–ff -1, -2 mates align fw&#x2F;rev, rev&#x2F;fw, fw&#x2F;fw (–fr) –no-mixed suppress unpaired alignments for paired reads –no-discordant suppress discordant alignments for paired reads Output: -t&#x2F;–time print wall-clock time taken by search phases –un write unpaired reads that didn’t align to –al write unpaired reads that aligned at least once to –un-conc write pairs that didn’t align concordantly to –al-conc write pairs that aligned concordantly at least once to (Note: for –un, –al, –un-conc, or –al-conc, add ‘-gz’ to the option name, e.g. –un-gz , to gzip compress output, or add ‘-bz2’ to bzip2 compress output.) –summary-file print alignment summary to this file. –new-summary print alignment summary in a new style, which is more machine-friendly. –quiet print nothing to stderr except serious errors –met-file send metrics to file at (off) –met-stderr send metrics to stderr (off) –met report internal counters &amp; metrics every secs (1) –no-head suppress header lines, i.e. lines starting with @ –no-sq suppress @SQ header lines –rg-id set read group id, reflected in @RG line and RG:Z: opt field –rg add (“lab:value”) to @RG line of SAM header. Note: @RG line only printed when –rg-id is set. –omit-sec-seq put ‘*’ in SEQ and QUAL fields for secondary alignments. Performance: -o&#x2F;–offrate override offrate of index; must be &gt;&#x3D; index’s offrate -p&#x2F;–threads number of alignment threads to launch (1) –reorder force SAM output order to match order of input reads –mm use memory-mapped I&#x2F;O for index; many ‘hisat2’s can share Other: –qc-filter filter out reads that are bad according to QSEQ filter –seed seed for random number generator (0) –non-deterministic seed rand. gen. arbitrarily instead of using read attributes –remove-chrname remove ‘chr’ from reference names in alignment –add-chrname add ‘chr’ to reference names in alignment –version print version information and quit -h&#x2F;–help print this usage message $hisat2-buildNo input sequence or sequence file specified!HISAT2 version 2.2.1 by Daehwan Kim (&#105;&#110;&#x66;&#112;&#104;&#105;&#x6c;&#x6f;&#64;&#103;&#x6d;&#97;&#105;&#x6c;&#x2e;&#x63;&#x6f;&#109;, http://www.ccb.jhu.edu/people/infphilo)Usage: hisat2-build [options]* reference_in comma-separated list of files with ref sequences hisat2_index_base write ht2 data to files with this dir&#x2F;basenameOptions: -c reference sequences given on cmd line (as ) –large-index force generated index to be ‘large’, even if ref has fewer than 4 billion nucleotides -a&#x2F;–noauto disable automatic -p&#x2F;–bmax&#x2F;–dcv memory-fitting -p number of threads –bmax max bucket sz for blockwise suffix-array builder –bmaxdivn max bucket sz as divisor of ref len (default: 4) –dcv diff-cover period for blockwise (default: 1024) –nodc disable diff-cover (algorithm becomes quadratic) -r&#x2F;–noref don’t build .3&#x2F;.4.ht2 (packed reference) portion -3&#x2F;–justref just build .3&#x2F;.4.ht2 (packed reference) portion -o&#x2F;–offrate SA is sampled every 2^offRate BWT chars (default: 5) -t&#x2F;–ftabchars # of chars consumed in initial lookup (default: 10) –localoffrate SA (local) is sampled every 2^offRate BWT chars (default: 3) –localftabchars # of chars consumed in initial lookup in a local index (default: 6) –snp SNP file name –haplotype haplotype file name –ss Splice site file name –exon Exon file name –repeat-ref Repeat reference file name –repeat-info Repeat information file name –repeat-snp Repeat snp file name –repeat-haplotype Repeat haplotype file name –seed seed for random number generator -q&#x2F;–quiet disable verbose output (for debugging) -h&#x2F;–help print detailed description of tool and its options –usage print this usage message –version print version information and quit","tags":[],"categories":[]},{"title":"hisat2 rsem 连用","date":"2022-07-16T02:19:15.000Z","path":"wiki/hisat2-rsem-连用/","text":"尝试使用rsem定量hisat2的比对结果，失败了 $rsem-calculate-expression –paired-end –alignments Ha5_Fb2.uniq.bam &#x2F;public2&#x2F;home&#x2F;qianwei&#x2F;project&#x2F;seahorse&#x2F;02.ref&#x2F;RsemIndex&#x2F;Ha_Rsem Ha5_Fb2rsem-parse-alignments &#x2F;public2&#x2F;home&#x2F;qianwei&#x2F;project&#x2F;seahorse&#x2F;02.ref&#x2F;RsemIndex&#x2F;Ha_Rsem Ha5_Fb2.temp&#x2F;Ha5_Fb2 Ha5_Fb2.stat&#x2F;Ha5_Fb2 Ha5_Fb2.uniq.bam 3 -tag XMWarning: The SAM&#x2F;BAM file declares less reference sequences (168) than RSEM knows (27642)! Please make sure that you aligned your reads against transcript sequences instead of genome.RSEM can not recognize reference sequence name Chr1!“rsem-parse-alignments &#x2F;public2&#x2F;home&#x2F;qianwei&#x2F;project&#x2F;seahorse&#x2F;02.ref&#x2F;RsemIndex&#x2F;Ha_Rsem Ha5_Fb2.temp&#x2F;Ha5_Fb2 Ha5_Fb2.stat&#x2F;Ha5_Fb2 Ha5_Fb2.uniq.bam 3 -tag XM” failed! Plase check if you provide correct parameters&#x2F;options for the pipeline! 原因分析：表面上这个报错是说 hisat2的bam文件跟 Rsem 的索引不兼容。实际上 rsem 不支持 gapped alignment的定量，hisat2在比对过程中使用的就是 gapped alignment，所以两个软件本质上就是不兼容的，不能连用。","tags":[],"categories":[]},{"title":"hexo/vsCode使用技巧","date":"2022-07-15T07:39:40.000Z","path":"wiki/hexo-vsCode使用技巧/","text":"ctrl+shift+L 选中编辑代码中相同的内容按住Ctrl + Alt，再按键盘上的上或下键，可以使一列上出现多个光标","tags":[],"categories":[]},{"title":"hexo/hexo_push_error","date":"2022-07-15T07:31:49.000Z","path":"wiki/2/hexo-push-error/","text":"hexo 向 git 上推送时，报错如下 kex_exchange_identification: read: Connection reset by peerConnection reset by 20.205.243.166 port 22fatal: Could not read from remote repository. Please make sure you have the correct access rightsand the repository exists.\u001b[41mFATAL\u001b[49m { err: Error: Spawn failed at ChildProcess. &gt;(D:\\gitpages\\node_modules\\hexo-util\\lib\\spawn.js:51:21) at ChildProcess.emit (node:events:527:28) at ChildProcess.cp.emit &gt;(D:\\gitpages\\node_modules\\cross-spawn\\lib\\enoent.js:34:29) at Process.ChildProcess._handle.onexit (node:internal&#x2F;&gt;child_process:291:12) { code: 128 }} Something’s wrong. Maybe you can find the solution here: %s \u001b[4mhttps:&#x2F;&#x2F;&gt;hexo.io&#x2F;docs&#x2F;troubleshooting.html\u001b[24m 分析：首先怀疑是本地不能正常连接到 github 所导致,测试连接是否正常 12D:\\gitpages&gt;ssh -T git@github.comkex_exchange_identification: read: Connection reset 确实是连接出了问题，尝试解决方法如下： 1234567891011121314D:\\gitpages&gt;ssh-keygen -R 20.205.243.166# Host 20.205.243.166 found: line 1C:\\Users\\sqw/.ssh/known_hosts updated.Original contents retained as C:\\Users\\sqw/.ssh/known_hosts.old#这里是重新生成了known_host文件D:\\gitpages&gt;ssh -T git@github.comThe authenticity of host &#x27;github.com (20.205.243.166)&#x27; can&#x27;t be established.ECDSA key fingerprint is SHA256:p2QAMXNIC1TJYWeIOttrVc98/R1BUFWu3/LiyKgUfQM.Are you sure you want to continue connecting (yes/no/[fingerprint])? yPlease type &#x27;yes&#x27;, &#x27;no&#x27; or the fingerprint: yesWarning: Permanently added &#x27;github.com,20.205.243.166&#x27; (ECDSA) to the list of known hosts.Hi sqwwww! You&#x27;ve successfully authenticated, but GitHub does not provide shell access.#本地重新把github的指纹加进known host文件里。 接下来执行 123hexo cleanhexo ghexo d 成功推送 gitpages默认branch是main，但我的主页设置在master，需要把默认branch从main改成master参照这篇 https://blog.csdn.net/xuchaoxin1375/article/details/111414527github允许每个仓库的default branch 可以单独设置","tags":[{"name":"bug, hexo, push","slug":"bug-hexo-push","permalink":"https://sqwwww.github.io/tags/bug-hexo-push/"}],"categories":[{"name":"2","slug":"2","permalink":"https://sqwwww.github.io/categories/2/"}]},{"title":"test","date":"2022-07-15T05:02:29.000Z","path":"wiki/test/","text":"seqkit seqkit subseq –bed Fhap1_dmrt1.name -o Fhap1_dmrt1.fasta ..&#x2F;hap_chro&#x2F;F_hap1.groups.asm.fasta","tags":[],"categories":[]},{"title":"SqwPersonal","date":"2022-07-15T04:49:53.000Z","path":"wiki/SqwPersonal/","text":"","tags":[],"categories":[]}],"categories":[{"name":"biosoft","slug":"biosoft","permalink":"https://sqwwww.github.io/categories/biosoft/"},{"name":"2","slug":"2","permalink":"https://sqwwww.github.io/categories/2/"}],"tags":[{"name":"bug, hexo, push","slug":"bug-hexo-push","permalink":"https://sqwwww.github.io/tags/bug-hexo-push/"}]}
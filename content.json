{"pages":[{"title":"About","date":"2022-09-03T02:52:42.014Z","path":"about/index.html","text":""},{"title":"Categories","date":"2022-09-03T02:52:42.015Z","path":"categories/index.html","text":""},{"title":"Tags","date":"2022-09-03T02:52:42.016Z","path":"tags/index.html","text":""}],"posts":[{"title":"shellCode","date":"2022-09-29T05:07:46.000Z","path":"wiki/codeSkill/shellCode/","text":"加法 1234i=0let &#x27;i+=1&#x27;echo &#x27;scale=2;2+3&#x27; | bc if 语句 123if [-e filename]for 语句 12 关联数组 123456789101112131415161718192021declare -A ass_array # 声明ass_array=([&quot;PE&quot;]=0 [&quot;PM&quot;]=0 [&quot;PL&quot;]=0 [&quot;PN&quot;]=0 [&quot;PB&quot;]=0) # 初始化cat ../../published/mbe_15/phenotype.txt |while read id; do srr=`echo $id|awk &#x27;&#123;print $1&#125;&#x27;`pheno=`echo $id|awk &#x27;&#123;print $NF&#125;&#x27;`fq1=/public2/home/qianwei/project/seahorse/published/mbe_15/$srr/$&#123;srr&#125;_1.fastq.gzfq2=/public2/home/qianwei/project/seahorse/published/mbe_15/$srr/$&#123;srr&#125;_2.fastq.gzlet &#x27;ass_array[$pheno]+=1&#x27; # 赋值 加法#echo $pheno $&#123;ass_array[$pheno]&#125;fq11=Ha$&#123;pheno&#125;_MPL$&#123;ass_array[$pheno]&#125;_raw_1.fastq.gzfq22=Ha$&#123;pheno&#125;_MPL$&#123;ass_array[$pheno]&#125;_raw_2.fastq.gz#echo $fq11ln -s $fq1 $fq11ln -s $fq2 $fq22done cp 123456#从软链接拷贝软链接（默认拷贝文件）,用-d选项ln -s $source link_filecp -d link_file $new_dir# 从文件拷贝软链接，用 -s 选项cp -s $source link_file find,xargs 12345678910# 按时间查找, find . &#123;-atime/-ctime/-mtime/-amin/-cmin/-mmin&#125; [-/+]num-1 一天内+1 一天前# 按名称查找 -name 参数# xargs传递参数，-i选项，可以把参数传递给&#123;&#125;find ../final_fq -mtime -1 -name &quot;Ha*&quot; | xargs -i cp -d &#123;&#125; ./# 显示link文件find /path -type l 加法 1234i=0let &#x27;i+=1&#x27;ratio=`echo &quot;scale=2;$&#123;sample1_cov&#125; / $&#123;sample2_cov&#125;&quot;|bc`;echo $ratio; 查看文件是否存在 1 参考资料","tags":[],"categories":[{"name":"codeSkill","slug":"codeSkill","permalink":"https://sqwwww.github.io/categories/codeSkill/"}]},{"title":"statisticTest","date":"2022-09-27T02:35:46.000Z","path":"wiki/knowledge/statisticTest/","text":"方差分析 ANOVA1.1 适合性检验检验数据是否符合某一理论分布1.2 独立性检验检验两组数据是否独立 多变量方差分析Multivariate analysis of variance (MANOVA) ，一元方差分析的推广有两个或者多个因变量的时候使用 参考资料","tags":[{"name":"statistic, ANOVA, MANOVA","slug":"statistic-ANOVA-MANOVA","permalink":"https://sqwwww.github.io/tags/statistic-ANOVA-MANOVA/"}],"categories":[{"name":"knowledge","slug":"knowledge","permalink":"https://sqwwww.github.io/categories/knowledge/"}]},{"title":"paperArrange","date":"2022-09-22T17:52:53.000Z","path":"wiki/knowledge/paperArrange/","text":"2016，nature，LinQiang测了虎尾海马(H.comes)的基因组,探究了海马没有牙齿，没有腹鳍；鉴定了一个pouch 怀孕相关的正在扩张的基因家族（patristacin），是choriolytic enzyme的相关基因 2022, molecular Ecology, Olivia Roth做了四个物种(He,Sros,Styp,Noph)，四个时期(None,earl,Late,Part),用了pca，差异基因分析，时序分析来寻找物种差异的基因和时期特异的基因。有一点还挺有趣的。pouched species 免疫相关的基因在早期出现了显著下调，晚期又显著上升；nopouched species则没有这样的规律。这些基因是一些抗原处理和呈递相关的基因。怀孕早期父体免疫反应的下降可能是为了达成immunological tolerance，让胚胎成功进入父体；晚期的上调则有可能是因为，这篇文章里推测是因为晚期的胚胎对父体的营养依赖减少了，不再直接与父体的免疫系统亲密接触；我觉得他说得不正确，越到后期对父体的营养依赖应该更强才对，因为卵黄在前中期逐渐被消耗完了，那么后期免疫反应的增强有可能是因为免疫反应可以试分娩顺利进行；但这个猜想也不完美，毕竟不是在分娩时期出现的下调 怀孕过程已经被证明是存在营养传递的2021, Placenta, C.M.Whittington，膨腹怀孕各时期的组织学切片 评估了膨腹海马怀孕时育儿袋之间物质交换的结构支持证据，从pouch inner layer的下列指标来论证 育儿袋inner layer的曲折程度（育儿袋内腔的表面积）在怀孕过程中增加 毛细血管与育儿袋内腔之间的扩散距离在怀孕过程中减少，即随着怀孕的进行，毛细血管越来越靠近胚胎 毛细血管的密度在怀孕过程中增加 这些结构上的显著变化为怀孕过程中父本和胚胎的物质交换提供了结构上的支持，其他基因水平的研究中也发现怀孕过程中血管生成(vasculogenic)和组织重塑(remodelling)的相关基因有明显上调2020, Journal of Comparative Physiology B, Camilla M. Whittington 评估了膨腹海马怀孕时父本和胚胎之间是否存在营养交换，主要看干重和脂质含量这两个指标。newly fertilised eggs 和 neonates相比，干重没有显著变化，脂质含量也没有显著变化。对严格的卵黄营养动物，由于卵黄的消耗，二者都应存在明显的下降。因此从这一方面论证了在胚胎的发育过程中，父本向胚胎传递了营养和脂质。 lipid contributed ~88% to Ha neonate dry mass Ha 一次怀孕是，一个繁殖期的不同批次的怀孕可以是 MHCII与个体嗅觉有关，参与个体择偶，抑制近亲繁殖 参考资料","tags":[],"categories":[{"name":"knowledge","slug":"knowledge","permalink":"https://sqwwww.github.io/categories/knowledge/"}]},{"title":"sbatchSystem","date":"2022-09-08T02:01:36.000Z","path":"wiki/codeSkill/sbatchSystem/","text":"sinfo查看计算节点空闲状态 idel为空闲，mix为节点部分核心可以使用，alloc为已被占用可以通过squeue查看已经提交作业的排队情况通过scontrol show job 和sacct查询作业的相关信息通过scancel取消已经提交的作业 参考资料","tags":[{"name":"集群","slug":"集群","permalink":"https://sqwwww.github.io/tags/%E9%9B%86%E7%BE%A4/"}],"categories":[{"name":"codeSkill","slug":"codeSkill","permalink":"https://sqwwww.github.io/categories/codeSkill/"}]},{"title":"pbsSystem","date":"2022-09-04T14:10:33.000Z","path":"wiki/codeSkill/pbsSystem/","text":"查询自己的id下有哪些任务在运行qstat -au fjnu_edu_hz 列出分配给此作业的节点qstat -n job_id 查看节点状态pestat 参考资料","tags":[{"name":"集群","slug":"集群","permalink":"https://sqwwww.github.io/tags/%E9%9B%86%E7%BE%A4/"}],"categories":[{"name":"codeSkill","slug":"codeSkill","permalink":"https://sqwwww.github.io/categories/codeSkill/"}]},{"title":"repeatMasker","date":"2022-09-03T12:01:26.000Z","path":"wiki/biosoft/repeatMasker/","text":"repeatmasker 的安装： Python 3 rmblast ~&#x2F;miniconda3&#x2F;envs&#x2F;repeatMask&#x2F;bin&#x2F;rmblastn trf ~&#x2F;miniconda3&#x2F;envs&#x2F;repeatMask&#x2F;bin&#x2F;trfrepeatModeler &#x2F;public2&#x2F;home&#x2F;qianwei&#x2F;miniconda3&#x2F;envs&#x2F;repeat&#x2F;bin&#x2F;perl &#x2F;public2&#x2F;home&#x2F;qianwei&#x2F;biosoft&#x2F;RepeatMasker &#x2F;public2&#x2F;home&#x2F;qianwei&#x2F;miniconda3&#x2F;envs&#x2F;repeat&#x2F;bin &#x2F;public2&#x2F;home&#x2F;qianwei&#x2F;miniconda3&#x2F;envs&#x2F;repeat&#x2F;bin UCSC TwoBit Tools (twoBitToFa, faToTwoBit, twoBitInfo etc) cd-hit recon repeatscout repeatmodeler运行内存需要32G，多核（示例用了28核），一般要跑2-3天 123456789101112131415161718192021222324#!/bin/bash -x#PBS -N mask#PBS -o mask.log#PBS -e mask.err#PBS -q share#PBS -j oe#PBS -l nodes=1:ppn=28cd $PBS_O_WORKDIRsource activate repeatMask#build genome database with name/public/home/fjnu_edu_hz/qianwei/biosoft/RepeatModeler-2.0.3/BuildDatabase -name Qsp Fhap1.chr.fasta#perform repeatseq from database/public/home/fjnu_edu_hz/qianwei/biosoft/RepeatModeler-2.0.3/RepeatModeler -pa 28 -database Qsp#get ortholog lib of ancestor and descendant species/public/home/fjnu_edu_hz/qianwei/biosoft/RepeatMasker/famdb.py -i RepeatMaskerLib.h5 families -f embl -ad frogs &gt; frogs.embl#transform/public/home/fjnu_edu_hz/qianwei/biosoft/RepeatMasker/util/buildRMLibFromEMBL.pl frogs.embl &gt; frogs.fasta#merge repeat libcat Qsp-families.fa frogs.fasta &gt; Qsp-allrep.fa#run mask/public/home/fjnu_edu_hz/qianwei/biosoft/RepeatMasker/RepeatMasker -pa 28 -lib ./Qsp-allrep.fa -e ncbi -dir mask -gff ./Fhap1.chr.fasta 结果展示repeat modeler 成功运行应出现如下结果， RepeatClassifier Version 2.0.3Search Engine &#x3D; rmblast Looking for Simple and Low Complexity sequences.. Looking for similarity to known repeat proteins.. Looking for similarity to known repeat consensi..Classification Time: 01:52:08 (hh:mm:ss) Elapsed Time Program Time: 43:21:32 (hh:mm:ss) Elapsed TimeWorking directory: &#x2F;public&#x2F;home&#x2F;fjnu_edu_hz&#x2F;qianwei&#x2F;wa&#x2F;mask&#x2F;Fhap1&#x2F;RM_229363.SunSep42308182022may be deleted unless there were problems with the run. The results have been saved to: Qsp-families.fa - Consensus sequences for each family identified. Qsp-families.stk - Seed alignments for each family identified. Qsp-rmod.log - Execution log. Useful for reproducing results. The RepeatModeler stockholm file is formatted so that it caneasily be submitted to the Dfam database. Please consider contributingcurated families to this open database and be a part of this growingcommunity resource. For more information contact &#104;&#x65;&#x6c;&#x70;&#64;&#100;&#x66;&#97;&#109;&#46;&#x6f;&#x72;&#x67;. 参考资料","tags":[],"categories":[{"name":"biosoft","slug":"biosoft","permalink":"https://sqwwww.github.io/categories/biosoft/"}]},{"title":"pregnancy","date":"2022-09-03T06:25:54.000Z","path":"wiki/knowledge/pregnancy/","text":"labour is a complex biological progress that in female pregnant animal is controled by hormones including oxytocin(催产素), which can induce contractions of smooth muscles in uterus.In female mammals, the uterine wall contains abundant smooth muscle, oxytocin stimulates this smooth muscle to contract, helping bringing the labour. when unpregnant male seahorses were exposed to fish version oxytocin(isotocin), they expressed labour-like behaviours.so it’s speculated that seahorse would use oxytocin-family hormones to control the process of giving birth. female mammals usually use smooth muscles to control the giving birth, but in male seahorse, the small smooth muscle bundles were only found to scattered in the out layer of pouch. the large skleton muscle associated with anal fin could control the opening of pouch under the regulatory of oxytocin-family hormones(https://www.abc.net.au/news/2022-09-02/seahorse-dad-father-give-birth-pregnant/101400086)muscle type smooth muscle skeletal muscle cardiac muscle decidua 蜕膜孕妇的子宫内膜，胚胎植入子宫蜕膜后，蜕膜可以分为三部分，位于胚胎深部的叫做基蜕膜（decidua strama），包被在胚胎表面的叫做包蜕膜，其余部分称壁蜕膜，其中基蜕膜参与构成胎盘，包蜕膜和壁蜕膜组成包衣的一部分。胎儿分娩时，蜕膜随从胎盘和包衣排出。 endometrium 子宫内膜During pregnancy, the endometrium becomes a specialized tissue(named decidua) with strikingly high proportion of leukocytes with unique regulatory function.Two major population are decidua macrophages and regulatory T cells, which plays important role in establishing tolerance and maintaining the homeostatic enviroment that is cruial for normal fetal development 滋养层 trophoblast哺乳动物早期胚泡壁的单层细胞所形成的薄膜，为以后从母体中摄取胎儿营养而得名 attachment phase，在真兽类和有袋类中都存在，在有袋类中，胚胎attachment会引起炎症反应，炎症反应被认为介导了最后的分娩eutherian implantation: establishment of a stable fetal-maternal interface, 在许多真兽类动物中，胚胎定植(embryo implantation)通常伴随着子宫(uterus)的炎症反应(inflammatory reaction),其中有些炎症反应对胚胎的成功定植是必要的。此时炎症反应在怀孕中的作用与在有袋类中是相反的，在有袋类中引起分娩，在真兽类中有利于定植。在真兽类中，胚胎定植的过程抑制了一类特定的炎症反应, 促炎(proinflammatory)细胞因子(cytokine) IL17A介导的 中性粒细胞(neutrophil)的招募(recruitment)，DSC(蜕膜基质)的分泌物可以抑制TH17 cells产生IL17A 炎症反应损伤的细胞分泌炎症细胞因子，炎症细胞因子（cytokine）诱导体内的炎症相关反应前列腺素（prostaglandins）在免疫反应中起着相当重要的作用 embryo retentionembryo retention 与胎生的进化非常相关。由于embryo retention 时间的不同，卵生动物在产卵（oviposition）时胚胎所处的时期也不同，retention的时间越久，胚胎发育的越成熟，可能处于的时期有 囊胚期blastula，原肠期gastrula，神经胚期后post-neurula embryo，完全成熟期viviparity allantois 尿囊进行气体交换，存储代谢废物，一般形成在chorion和amnion之间 参考资料","tags":[{"name":"paperReading, teacher","slug":"paperReading-teacher","permalink":"https://sqwwww.github.io/tags/paperReading-teacher/"}],"categories":[{"name":"knowledge","slug":"knowledge","permalink":"https://sqwwww.github.io/categories/knowledge/"}]},{"title":"","date":"2022-09-03T02:52:42.023Z","path":"wiki/pipeline/RNA流程/","text":"","tags":[],"categories":[{"name":"pipeline","slug":"pipeline","permalink":"https://sqwwww.github.io/categories/pipeline/"}]},{"title":"","date":"2022-09-03T02:52:42.020Z","path":"wiki/biosoft/error/errorRecord/","text":"vcftools 12345[W::bcf_hdr_check_sanity] GL should be declared as Number=G[W::vcf_parse] Contig &#x27;Chr0_RagTag&#x27; is not defined in the header. (Quick workaround: index the file with tabix.)[W::vcf_parse] Contig &#x27;ctg102_pilon_pilon_RagTag&#x27; is not defined in the header. (Quick workaround: index the file with tabix.)Warning: Expected at least 2 parts in INFO entry: ID=Source,Number=.,Type=String,Description=&quot;Was this variant suggested by Playtypus, Assembler, or from a VCF?&quot;&gt; 这两个warning好像都可以忽略。暂时不处理了如果运行 bcftools 出现如下错误，说明需要对 vcf 创建索引文件tabix -fp vcf XXX.vcf.gz","tags":[],"categories":[{"name":"biosoft","slug":"biosoft","permalink":"https://sqwwww.github.io/categories/biosoft/"},{"name":"error","slug":"biosoft/error","permalink":"https://sqwwww.github.io/categories/biosoft/error/"}]},{"title":"Hello World","date":"2022-09-03T02:52:42.017Z","path":"wiki/tmp/hello-world/","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","tags":[],"categories":[{"name":"tmp","slug":"tmp","permalink":"https://sqwwww.github.io/categories/tmp/"}]},{"title":"bwa","date":"2022-08-13T05:43:13.000Z","path":"wiki/biosoft/bwa/","text":"bwa index [ –p prefix ] &lt;in.db.fasta&gt; bwa mem -t 25 $genome $read1 $read2 | samtools sort -@ 10 -m 3G -O BAM -o $genome.$sample.sorted.bam - samtools index $genome.$sample.sorted.bam 参考资料","tags":[],"categories":[{"name":"biosoft","slug":"biosoft","permalink":"https://sqwwww.github.io/categories/biosoft/"}]},{"title":"genoPlotR","date":"2022-08-12T08:17:54.000Z","path":"wiki/codeSkill/genoPlotR/","text":"genoPlotR是用来展示基因组结构的R包 基础的结构绘制 参考资料","tags":[],"categories":[{"name":"codeSkill","slug":"codeSkill","permalink":"https://sqwwww.github.io/categories/codeSkill/"}]},{"title":"lipidDroplet","date":"2022-08-08T03:16:50.000Z","path":"wiki/knowledge/lipidDroplet/","text":"lipid droplet biology lipid是什么最主要的能量储存形式以甘油三酯（最主要），兹醇酯，蜡酯等形式存储用作能量储存的优点：能量密度高；高度还原，可用于氧化；存储过程不需要水的参与 lipid droplet是什么是一种存储油脂的细胞器，磷脂单分子层外膜，中间包裹着中性的脂质核心，脂质核心中通常含有甘油三酯（最主要），兹醇酯，蜡酯等；磷脂单分子层外膜通常被蛋白修饰，这些蛋白一般会参加脂质的代谢过程 lipid droplet 与细胞质脂滴在细胞质中以小液滴的形式存在，形成乳浊液，连续相是胞浆，分散相是脂滴。 lipid droplet 在多细胞动物中的分布ubiquitous，在人中，几乎所有细胞都能合成脂滴；但是脂质的存储主要在脂肪组织（adipose tissue）中。 脂滴的分泌乳腺上皮细胞分泌牛奶（牛奶含有大量脂肪），就存在大量的脂滴分泌过程 脂滴的合成脂滴合成通路 合成甘油三酯: DGAT（ER表面），合成的甘油三酯被输送到ER的磷脂双分子层中间的空腔 脂滴在ER上合成的起始阶段: seipin（ER表面）,LPAF1(ER表面，脂滴表面)，合成的甘油三酯在ER特定位置堆积，靠近胞质的磷脂层隆起，出芽，直至脂滴与内质网分离，LPAF1在这一过程中也从内质网表面进入到脂滴表面。 脂滴与ER分离，并招募表面蛋白：两种途径，从细胞质中招募；从内质网上招募（GPAT4） 脂滴进一步生长成熟 perlin 蛋白： 合成于游离核糖体 mammal中含有5种perilipin蛋白，Perilipins 2 and 3在所有组织中都表达，145具有组织特异性。teleost中含有4种perilipin蛋白，其中perilipin6是teleost特有的。皮肤黄色素细胞（xanthophores）中含有包裹类胡萝卜素的脂滴，perilipin6就集中在这一类脂滴上，促进相关色素的聚集和浓度提高，与鱼的体色相关。哺乳动物中包裹视黄醇（维生素A，可以由胡萝卜素转变而成）的脂滴表面富集perilipin2和3。 鱼类具备6种起源于神经嵴（Neural crest）的色素细胞，分别为黑色素细胞（Melanophores）、黄色素细胞（Xanthophores）、红色素细胞（Erythrophores）、彩虹细胞（Iridophores），白色素细胞（Leucophores）和蓝色素细胞（Cyanophores）。哺乳类和鸟类仅含有1种神经嵴起源的色素细胞类型，即黑素细胞（Melanocytes）。鱼类色素细胞主要存在于表皮的真皮中，其中黑色素细胞、黄色素细胞、红色素细胞和蓝色素细胞含有相应的色素物质。 所有硬骨鱼类的色素细胞均起源于胚胎时期外胚层的神经嵴细胞群，由一小组神经嵴细胞群首先形成色素母细胞（Chromatoblasts），随着发育的进行，再分化为黑色素细胞、黄色素细胞和彩虹色素细胞等其他色素细胞，在色素细胞到达一定的数量，开始色素模式的形成，也就是我们看到的成体鱼类所具有的典型的条纹和色素斑点。 plin6在斑马鱼的胚胎发育时期可以检测到表达，在成年个体的皮肤上高表达 正常情况下，未磷酸化的perilipin蛋白包裹在脂滴表面，阻碍脂质降解蛋白接触到脂滴内的脂质，从而使脂滴的的脂质可以存储下来；当perilipin蛋白处于激发态的时候（被PKA磷酸化），HSL（脂肪酶）与磷酸化的perilipin共定位于脂滴表面，HSL更容易接触到脂滴内的脂质，从而发挥脂解作用。 HSL是水解甘油三酯的脂肪酶，非活化状态的HSL存在于细胞质中 脂质如何通过胎盘 正常情况下脂质很难通过胎盘，甘油三脂不能通过扩散进入细胞，但可以以两种方式进入胎盘，为胎儿提供营养 1. 脂质与蛋白结合形成脂蛋白，胎盘上有脂蛋白的受体，可以把脂蛋白转运进胎盘。 2. 脂肪酸可以通过自由扩散进入胎盘，这就需要母体有比较高的脂肪酸浓度。 特殊情况：乳腺上皮可以分泌脂滴 lipoprotein脂蛋白和lipid droplet脂滴是一个东西吗 不是，二者结构上比较相似，都是由中性脂质内核和磷脂单分子外膜构成，外膜上存在蛋白。但是不同点如下：大小不同，脂滴（100nm - 100 um）比脂蛋白（20-500 nm）要大很多；功能不同，脂滴主要用做细胞内脂质的储存，脂蛋白主要用作脂质在血液中的运输，因此二者表面的蛋白种类差异也很大。几乎所有的细胞都能合成脂滴，但只有少部分的细胞类型可以合成脂蛋白组装需要的特殊蛋白（比如载脂蛋白apoB，apolipoprotein B 和microsomal TG transfer protein） 参考资料","tags":[],"categories":[{"name":"knowledge","slug":"knowledge","permalink":"https://sqwwww.github.io/categories/knowledge/"}]},{"title":"blast","date":"2022-08-07T10:12:35.000Z","path":"wiki/biosoft/blast/","text":"pep_fa&#x3D;Habd.faamakeblastdb -in $pep_fa -dbtype prot -out blastIndex&#x2F;Ha_pep blastp -query $qry_fa -out $out_name -db $index -outfmt 6 -evalue 1e-5 -num_threads 11 -max_target_seqs 6 tblastn -query $qry_fa -out $out_name -db $index -outfmt 6 -evalue 1e-5 -num_threads 11 -max_target_seqs 1blastp输出结果 qseqid query (e.g., unknown gene) sequence id sseqid subject (e.g., reference genome) sequence id pident percentage of identical matches length alignment length (sequence overlap) mismatch number of mismatches gapopen number of gap openings qstart start of alignment in query qend end of alignment in query sstart start of alignment in subject send end of alignment in subject evalue expect value bitscore bit score blast 参数详细如果只想取query的最优比对，设置 -max_target_seqs 1；自我比对的时候只会得到原始序列想要每个query-subject的唯一最优对应，设置 -max_target_seqs 500 -max_hsps 1 blastdbcmd 从blast构建好的数据库中提取序列 blatref_fa&#x3D;qry_fa&#x3D;out_name&#x3D;blat -t&#x3D;dna -q&#x3D;dna $ref_fa $qry_fa $out_name nucmer nucmer -p $1_$2 $ref $querynucmer fhap1_chr1.fa fhap2_chr1.fa &amp;&gt; fhap12.log&#x2F;public&#x2F;home&#x2F;Zexian&#x2F;mummer3&#x2F;MUMmer3.23&#x2F;delta-filter -1 out.delta &gt; filter.delta &#x2F;public&#x2F;home&#x2F;Zexian&#x2F;mummer3&#x2F;MUMmer3.23&#x2F;show-coords -T -q -H filter.delta &gt; XR_coord.txt 参考资料","tags":[],"categories":[{"name":"biosoft","slug":"biosoft","permalink":"https://sqwwww.github.io/categories/biosoft/"}]},{"title":"fish","date":"2022-08-05T08:30:12.000Z","path":"wiki/knowledge/fish/","text":"脊椎动物亚门vertebrate 圆口纲 软骨鱼纲 硬骨鱼纲 两栖纲 爬行纲 鸟纲 哺乳纲 参考资料","tags":[],"categories":[{"name":"knowledge","slug":"knowledge","permalink":"https://sqwwww.github.io/categories/knowledge/"}]},{"title":"fastq-dump","date":"2022-07-30T15:54:51.000Z","path":"wiki/biosoft/fastq-dump/","text":"fastq-dump –gzip –split-3 SRR12601728.sra，用了两个小时，真慢–split-3智能检测是单端还是双端的readsfastqc查看是否为clean reads 参考资料","tags":[],"categories":[{"name":"biosoft","slug":"biosoft","permalink":"https://sqwwww.github.io/categories/biosoft/"}]},{"title":"coverage_pipeline","date":"2022-07-28T09:45:49.000Z","path":"wiki/pipeline/coverage-pipeline/","text":"从bam文件到coveragesambamba depth window –overlap 2500 -w 5000 -o female_Mhap1_depth.txt -t 28 -q&#x3D;30 $bam 得到用来做normalise的depth 12345file=$1samtools stats $file &gt; $&#123;file&#125;_tempnumber=$(grep ^COV $&#123;file&#125;_temp | cut -f 2- | awk -v max=0 &#x27;&#123;if($3&gt;max)&#123;want=$2; max=$3&#125;&#125;END&#123;print want&#125; &#x27; -)rm $&#123;file&#125;_tempecho $file $number &gt; $&#123;file&#125;_modal_depth.txt 参考资料","tags":[],"categories":[{"name":"pipeline","slug":"pipeline","permalink":"https://sqwwww.github.io/categories/pipeline/"}]},{"title":"R","date":"2022-07-25T04:40:17.000Z","path":"wiki/codeSkill/R/","text":"data.table 赋值 df_combined[,’:&#x3D;’(‘1_2’ &#x3D; sub1 &gt; sub2, ‘1_3’ &#x3D; sub1 &gt; sub3, ‘1_4’ &#x3D; sub1 &gt; sub4, ‘1_5’ &#x3D; sub1&gt; sub5, ‘2_3’ &#x3D; sub2&gt;sub3, ‘2_4’&#x3D; sub2&gt;sub4,’2_5’&#x3D; sub2&gt;sub5, ‘3_4’&#x3D;sub3&gt;sub4, ‘3_5’&#x3D;sub3&gt;sub5, ‘4_5’&#x3D;sub4&gt;sub5)] DT[i, c(“LHS1”, “LHS2”) :&#x3D; list(RHS1, RHS2), by &#x3D; …] window变region myWindow[order(CN, S,E), g := .(cumsum(c(0L,(shift(S, -1) &gt; cummax(E))[-.N]))),by = CN] myRegion &lt;- myWindow[order(CN,S,E),.(NS = min(S), NE = max(E), num = .N, log = mean(log2MFR)), by = .(CN, g)] df_combined_filtered[order(CHROM, BIN_START,BIN_END), g := .(cumsum(c(0L,(shift(BIN_START, -1) &gt; cummax(BIN_END))[-.N]))),by = CHROM] myRegion &lt;- df_combined_filtered[order(CHROM, BIN_START,BIN_END),.(NS = min(S), NE = max(E), num = .N, by = .(CHROM, g)] 根据向量选取列（select multiple columns using a character vector） 1234columns &lt;- c(&#x27;mpg&#x27;, &#x27;cyl&#x27;, &#x27;disp&#x27;)mtcars_dt[, columns, with=FALSE]mtcars_dt[, .(mpg, cyl, gear)] 对某一列重命名 setnames(tmp_data, &quot;gene_id&quot;, current_sampleID) Pitching[ , .SD, .SDcols = c(&#39;W&#39;, &#39;L&#39;, &#39;G&#39;)] DT[i, c(&quot;LHS1&quot;, &quot;LHS2&quot;) := list(RHS1, RHS2), by = ...] 填补NA replace_na(df$X1,5) # 把df的X1列中的NA填充为5 改变列的数据类型 mRNA_gff[, V3:= lapply(V3, as.numeric)] setkey和setkeyv 用来对data table 进行排序，setkey是根据一列排，setkeyv可以根据多列排 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465 a &lt;- fread(file = paste0(&quot;../published/NC21/&quot;,samp,&quot;_depth.txt&quot;)) setnames(a, &quot;# chrom&quot;, &quot;chrom&quot;) setnames(a, &quot;meanCoverage&quot;, &quot;samp&quot;) tmp_1 &lt;- a[,.(chrom,chromStart,chromEnd, samp)] setkeyv(tmp_1, c(&quot;chrom&quot;,&quot;chromStart&quot;,&quot;chromEnd&quot;))dylyrfilterraw_ortho %&gt;% filter_all(all_vars(. != &quot;N&quot;))msleep %&gt;% select(name, sleep_total) %&gt;% filter(between(sleep_total, 16, 18))msleep %&gt;% select(name, sleep_total) %&gt;% filter(near(sleep_total, 17, tol = sd(sleep_total)))msleep %&gt;% select(order, name, sleep_total) %&gt;% filter(order %in% c(&quot;Didelphimorphia&quot;, &quot;Diprotodontia&quot;))msleep %&gt;% select(order, name, sleep_total) %&gt;% filter(!order %in% remove)msleep %&gt;% select(name, sleep_total) %&gt;% filter(str_detect(tolower(name), pattern = &quot;mouse&quot;)) #filter(grepl(pattern=&quot;mouse&quot;, tolower(name)))filter(condition1, condition2)filter(condition1, !condition2)filter(condition1 | condition2) # return rows where condition 1 and/or condition 2 is met.filter(xor(condition1, condition2) # return all rows where only one of the conditions is met, and not when both conditions are met.# 删除某一列含有NA的行msleep %&gt;% select(name, conservation:sleep_cycle) %&gt;% filter(!is.na(conservation))#根据多列进行过滤 filter_all() will filter all columns based on your further instructions filter_if() requires a function that returns a boolean to indicate which columns to filter on. If that is true, the filter instructions will be followed for those columns. filter_at() requires you to specify columns inside a vars() argument for which the filtering will be done. any_vars() statement is equivalent to OR all_vars() statement is equivalent to AND msleep %&gt;% select(name:order, sleep_total, -vore) %&gt;% filter_all(any_vars(str_detect(., pattern = &quot;Ca&quot;))) msleep %&gt;% select(name, sleep_total:bodywt) %&gt;% filter_all(any_vars(. &lt; 0.1)) msleep %&gt;% select(name:order, sleep_total:sleep_rem) %&gt;% filter_if(is.character, any_vars(is.na(.))) # is.numeric, is.integer, is.double, is.logical, is.factor msleep %&gt;% select(name, sleep_total:sleep_rem, brainwt:bodywt) %&gt;% filter_at(vars(sleep_total, sleep_rem), all_vars(.&gt;5)) #all_vars() if all columns need to return TRUE (AND equivalent) # you can just select columns to which the change should happen via the vars() msleep %&gt;% select(name, sleep_total:sleep_rem, brainwt:bodywt) %&gt;% filter_at(vars(contains(&quot;sleep&quot;)), all_vars(.&gt;5)) #any_vars() in case just one variable needs to return TRUE (OR equivalent) 参考资料","tags":[],"categories":[{"name":"codeSkill","slug":"codeSkill","permalink":"https://sqwwww.github.io/categories/codeSkill/"}]},{"title":"data.table用法","date":"2022-07-25T04:40:17.000Z","path":"wiki/codeSkill/shell技巧/","text":"加法 1234i=0let &#x27;i+=1&#x27;echo &#x27;scale=2;2+3&#x27; | bc if 语句 123if [-e filename]for 语句 12 关联数组 123456789101112131415161718192021declare -A ass_array # 声明ass_array=([&quot;PE&quot;]=0 [&quot;PM&quot;]=0 [&quot;PL&quot;]=0 [&quot;PN&quot;]=0 [&quot;PB&quot;]=0) # 初始化cat ../../published/mbe_15/phenotype.txt |while read id; do srr=`echo $id|awk &#x27;&#123;print $1&#125;&#x27;`pheno=`echo $id|awk &#x27;&#123;print $NF&#125;&#x27;`fq1=/public2/home/qianwei/project/seahorse/published/mbe_15/$srr/$&#123;srr&#125;_1.fastq.gzfq2=/public2/home/qianwei/project/seahorse/published/mbe_15/$srr/$&#123;srr&#125;_2.fastq.gzlet &#x27;ass_array[$pheno]+=1&#x27; # 赋值 加法#echo $pheno $&#123;ass_array[$pheno]&#125;fq11=Ha$&#123;pheno&#125;_MPL$&#123;ass_array[$pheno]&#125;_raw_1.fastq.gzfq22=Ha$&#123;pheno&#125;_MPL$&#123;ass_array[$pheno]&#125;_raw_2.fastq.gz#echo $fq11ln -s $fq1 $fq11ln -s $fq2 $fq22done cp 123456#从软链接拷贝软链接（默认拷贝文件）,用-d选项ln -s $source link_filecp -d link_file $new_dir# 从文件拷贝软链接，用 -s 选项cp -s $source link_file find,xargs 12345678910# 按时间查找, find . &#123;-atime/-ctime/-mtime/-amin/-cmin/-mmin&#125; [-/+]num-1 一天内+1 一天前# 按名称查找 -name 参数# xargs传递参数，-i选项，可以把参数传递给&#123;&#125;find ../final_fq -mtime -1 -name &quot;Ha*&quot; | xargs -i cp -d &#123;&#125; ./# 显示link文件find /path -type l 加法 1234i=0let &#x27;i+=1&#x27;ratio=`echo &quot;scale=2;$&#123;sample1_cov&#125; / $&#123;sample2_cov&#125;&quot;|bc`;echo $ratio; 查看文件是否存在 1 参考资料","tags":[],"categories":[{"name":"codeSkill","slug":"codeSkill","permalink":"https://sqwwww.github.io/categories/codeSkill/"}]},{"title":"ragtag使用","date":"2022-07-18T15:54:44.000Z","path":"wiki/biosoft/ragtag使用/","text":"ragtag.py scaffold &lt;reference.fa&gt; &lt;query.fa&gt; scaffolding options: -e &lt;exclude.txt&gt; list of reference sequences to ignore [null] -j &lt;skip.txt&gt; list of query sequences to leave unplaced [null] -J &lt;hard-skip.txt&gt; list of query headers to leave unplaced and exclude from ‘chr0’ (‘-C’) [null] -f INT minimum unique alignment length [1000] –remove-small remove unique alignments shorter than ‘-f’ -q INT minimum mapq (NA for Nucmer alignments) [10] -d INT maximum alignment merge distance [100000] -i FLOAT minimum grouping confidence score [0.2] -a FLOAT minimum location confidence score [0.0] -s FLOAT minimum orientation confidence score [0.0] -C concatenate unplaced contigs and make ‘chr0’ -r infer gap sizes. if not, all gaps are 100 bp -g INT minimum inferred gap size [100] -m INT maximum inferred gap size [100000] input&#x2F;output options: -o PATH output directory [.&#x2F;ragtag_output] -w overwrite intermediate files -u add suffix to unplaced sequence headers mapping options: -t INT number of minimap2&#x2F;unimap threads [1] –aligner PATH aligner executable (‘nucmer’, ‘unimap’ or ‘minimap2’) [minimap2] –mm2-params STR space delimited minimap2 parameters (overrides ‘-t’) [‘-x asm5’] –unimap-params STR space delimited unimap parameters (overrides ‘-t’) [‘-x asm5’] –nucmer-params STR space delimted nucmer parameters [‘–maxmatch -l 100 -c 500’] -C会将没地方放的contig&#x2F;scaffold连在一起放到chr0中（中间用100个N连接） ragtag.py scaffold -u $ref $query -t 20 -C cd ~&#x2F;project&#x2F;seahorse&#x2F;published&#x2F;assembly&#x2F;ragtagbash ragtag.sh &amp;&gt; He_log cd ~&#x2F;project&#x2F;seahorse&#x2F;published&#x2F;assembly&#x2F;map&#x2F;refln -s &#x2F;public2&#x2F;home&#x2F;qianwei&#x2F;project&#x2F;seahorse&#x2F;published&#x2F;assembly&#x2F;ragtag&#x2F;ragtag_output_He&#x2F;ragtag.scaffold.fasta subelongatus.fabash bowtie2Index.sh &amp;&gt; sub_build.logcd ..bash DNApipeline.sh &amp;&gt; sub.map.log 参考资料","tags":[],"categories":[{"name":"biosoft","slug":"biosoft","permalink":"https://sqwwww.github.io/categories/biosoft/"}]},{"title":"bowtieAndBowtie2","date":"2022-07-16T09:01:36.000Z","path":"wiki/biosoft/bowtieAndBowtie2/","text":"bowtie和bowtie2的区别这两个软件都适合DNA的比对，bowtie开发的比较早，适合短reads（50bp）的比对，bowtie2适合长一点的reads（150bp）的比对，现在的数据基本上都适合用bowtie2 bowtie2 如何选择 uniq mapping 的 reads 1grep &quot;AS:&quot; aligned.sam | grep -v &quot;XS:i&quot; hisat比的话 grep “NH:i:1” aligned.sam | grep -v “ZS:i” bowtie2 建立索引 1bowtie2-build --threads 25 $fa bowtie2Index/Ha bowtie2 比对 12345678910111213141516ref=~/project/brain/ref/bowtie2-index/dmel-r6.12cores=12cat clean_list|while read id; do arr=($id) fq1=$&#123;arr[0]&#125; fq2=$&#123;arr[1]&#125; prefix=`basename $fq1 _clean_R1.fq.gz` echo $&#123;prefix&#125;-------------------------------------------------------------------------------- bowtie2 -p $&#123;cores&#125; \\ -x $&#123;ref&#125; \\ -1 $&#123;fq1&#125; \\ -2 $&#123;fq2&#125; \\ -S $&#123;prefix&#125;.sam done $bowtie2-build -hBowtie 2 version 2.3.5.1 by Ben Langmead (&#x6c;&#x61;&#x6e;&#103;&#109;&#x65;&#x61;&#x40;&#x63;&#x73;&#x2e;&#x6a;&#x68;&#x75;&#46;&#x65;&#x64;&#x75;, www.cs.jhu.edu/~langmea)Usage: bowtie2-build [options]* reference_in comma-separated list of files with ref sequences bt2_index_base write bt2 data to files with this dir&#x2F;basename*** Bowtie 2 indexes work only with v2 (not v1). Likewise for v1 indexes. ***Options: -f reference files are Fasta (default) -c reference sequences given on cmd line (as ) –large-index force generated index to be ‘large’, even if ref has fewer than 4 billion nucleotides –debug use the debug binary; slower, assertions enabled –sanitized use sanitized binary; slower, uses ASan and&#x2F;or UBSan –verbose log the issued command -a&#x2F;–noauto disable automatic -p&#x2F;–bmax&#x2F;–dcv memory-fitting -p&#x2F;–packed use packed strings internally; slower, less memory –bmax max bucket sz for blockwise suffix-array builder –bmaxdivn max bucket sz as divisor of ref len (default: 4) –dcv diff-cover period for blockwise (default: 1024) –nodc disable diff-cover (algorithm becomes quadratic) -r&#x2F;–noref don’t build .3&#x2F;.4 index files -3&#x2F;–justref just build .3&#x2F;.4 index files -o&#x2F;–offrate SA is sampled every 2^ BWT chars (default: 5) -t&#x2F;–ftabchars # of chars consumed in initial lookup (default: 10) –threads # of threads –seed seed for random number generator -q&#x2F;–quiet verbose output (for debugging) -h&#x2F;–help print detailed description of tool and its options –usage print this usage message –version print version information and quit $bowtie2 -hBowtie 2 version 2.3.5.1 by Ben Langmead (&#108;&#97;&#x6e;&#103;&#x6d;&#x65;&#x61;&#64;&#x63;&#115;&#46;&#106;&#x68;&#x75;&#46;&#x65;&#x64;&#117;, www.cs.jhu.edu/~langmea)Usage: bowtie2 [options]* -x {-1 -2 | -U | –interleaved | -b } [-S ] Index filename prefix (minus trailing .X.bt2). NOTE: Bowtie 1 and Bowtie 2 indexes are not compatible. Files with #1 mates, paired with files in . Could be gzip’ed (extension: .gz) or bzip2’ed (extension: .bz2). Files with #2 mates, paired with files in . Could be gzip’ed (extension: .gz) or bzip2’ed (extension: .bz2). Files with unpaired reads. Could be gzip’ed (extension: .gz) or bzip2’ed (extension: .bz2). Files with interleaved paired-end FASTQ&#x2F;FASTA reads Could be gzip’ed (extension: .gz) or bzip2’ed (extension: .bz2). Files are unaligned BAM sorted by read name. File for SAM output (default: stdout) 参考资料","tags":[],"categories":[{"name":"biosoft","slug":"biosoft","permalink":"https://sqwwww.github.io/categories/biosoft/"}]},{"title":"DNA比对流程","date":"2022-07-16T09:01:36.000Z","path":"wiki/pipeline/DNA比对流程/","text":"用来 call coverage 和 snp 的流程，从reads到结果图 ref&#x3D;ref&#x2F;bowtie2Index&#x2F;subthreads&#x3D;20cat fq_list|while read id; do arr=($id) fq1=$&#123;arr[0]&#125; fq2=$&#123;arr[1]&#125; sample=`basename $fq1 _1.fq.gz` echo $&#123;sample&#125;-------------------------- fastp -i $fq1\\ -I $fq2\\ -o fq/$&#123;sample&#125;_clean_1.fastq.gz \\ -O fq/$&#123;sample&#125;_clean_2.fastq.gz \\ --thread=$threads bowtie2 -p $&#123;threads&#125; \\ -x $&#123;ref&#125; \\ -1 fq/$&#123;sample&#125;_clean_1.fastq.gz \\ -2 fq/$&#123;sample&#125;_clean_2.fastq.gz \\ -S $&#123;sample&#125;.sam grep -P &#39;@|AS:&#39; $&#123;sample&#125;.sam | grep -v &quot;XS:i&quot; &gt; $&#123;sample&#125;.uniq.sam samtools view -@ 10 -bS $&#123;sample&#125;.uniq.sam | samtools sort -o $&#123;sample&#125;.uniq.bam samtools index $&#123;sample&#125;.uniq.bam done sexfindR的流程 call coverage 用到了 difcover，依赖到bioconductor-dnacopy，安装在 chipseq-py36下了 12(chipseq-py36) qianwei ~/project/seahorse/published/assembly/map$conda install -c bioconda bioconductor-dnacopy","tags":[],"categories":[{"name":"pipeline","slug":"pipeline","permalink":"https://sqwwww.github.io/categories/pipeline/"}]},{"title":"gatk_snp流程.md","date":"2022-07-16T09:01:36.000Z","path":"wiki/pipeline/gatk_snp流程/","text":"gatk官方博文，描述 gatk4和之前版本的差异 http://broad.io/GATK4-1一些terra上的实例：https://terra.bio/#library/showcase 数据预处理：map bam文件中会包含read group的信息，在之后的分析中要用到mark duplicatesrecalibrate base quality score（BQSR）：对machine error（包含pcr error和测序error）重新校准analysis-ready bam 多样本可以做joint calling 对每个样本单独call snp，得到 gvcf（包含基因组上所有位点的信息） 用所有样本的gvcf 做一个 joint calling，筛选出至少一个样本中存在变异的位点 建立索引nohup ~&#x2F;biosoft&#x2F;gatk-4.1.9.0&#x2F;gatk CreateSequenceDictionary -R subelongatus.fa -O gatk.dict &amp;&gt; gatkIndex.log &amp; gatk必须要sam&#x2F;bam文件的头文件信息（reads group），其中ID，PL和SM信息是必须要的若是忘记添加read group信息还以通过 AddOrReplaceReadGroups 添加GATK 要求read group的格式ID &#x3D; Read group identifier 每一个read group 独有的ID，每一对reads 均有一个独特的ID，可以自定义命名；PL &#x3D; Platform 测序平台；ILLUMINA, SOLID, LS454, HELICOS and PACBIO，不区分大小写；SM &#x3D; sample reads属于的样品名；SM要设定正确，因为GATK产生的VCF文件也使用这个名字;LB &#x3D; DNA preparation library identifier 对一个read group的reads进行重复序列标记时，需要使用LB来区分reads来自那条lane;有时候，同一个库可能在不同的lane上完成测序;为了加以区分， 同一个或不同库只要是在不同的lane产生的reads都要单独给一个ID. 一般无特殊说明，成对儿read属于同一库，可自定义，比如：library1 gatk AddOrReplaceReadGroups -I .bam -O .add.bam -LB library1 -PL illumina -PU pl1 -SM name 1234567891011121314151617181920212223242526272829303132333435363738394041424344#build dbbowtie2-build --threads 40 ./turtle.zjuv1.fa tt#get map.shls ../00.dnaData/*.fastq| xargs -n1 | awk &#x27;NR%2!=0&#123;print&quot;-1 &quot;$0&#125;NR%2==0&#123;print&quot;-2 &quot;$0&#125;&#x27; |xargs -n4 | while read line ;do echo &quot;bowtie2 -p 20 -x tt &quot;$line&quot; | samtools view -bS - &gt; &quot; &gt;&gt; map.log ;donels ../00.dnaData/*.fastq|xargs -n2 | cut -d&quot; &quot; -f1 | sed &#x27;s/\\..*SRR/SRR/g&#x27; | sed &#x27;s/\\_.*fastq//g&#x27; | awk &#x27;&#123;print$0&quot;.bam &amp;&quot;&#125;&#x27;&gt; bamname.logpaste map.log bamname.log | awk &#x27;NR%10==0&#123;print$0&quot;\\nwait&quot;&#125;NR%10!=0&#123;print$0&#125;&#x27;|sed &#x27;s/\\t/ /g&#x27; &gt; map.shnohup ./map.sh#bam input preparels *.bam | xargs -n1 | while read line ;do echo &quot;samtools view -bS &quot;$line&quot; -t ./turtle.zjuv1.fa.fai -o&quot; $line.fai.bam&quot; &amp;&quot; &gt;&gt; step1.sh;done ./step1.shls *.fai.bam | xargs -n1 | while read line ;do echo &quot;samtools sort -@ 10 -m 10G &quot;$line&quot; -o &quot;$line.sorted&quot; &amp;&quot; &gt;&gt; step2.sh ;done./step2.sh#add headls *.sorted| xargs -n1| while read line ;do echo &quot;/public1/home/yifeng/yifeng/tools/java/jdk1.8.0_271/bin/java -Xmx10G -jar /public1/home/yifeng/yifeng/tools/anaconda3/envs/py3/share/picard-2.23.8-0/picard.jar AddOrReplaceReadGroups I=/public1/home/Zexian/turtle_proj/19.recombination_rate/01.bowtie/&quot;$line&quot; O=/public1/home/Zexian/turtle_proj/19.recombination_rate/01.bowtie/&quot;$line.addhead&quot; RGLB=lib&quot;$line&quot; RGPL=ILLUMINA RGPU=unit1 RGSM=20 &amp;&quot; &gt;&gt; addhead.sh;done#这里RGSM=后面的20记得改 改成sample name./addhead.sh#resortls *.addhead |xargs -n 1 | while read line ; do echo &quot;/public1/home/yifeng/yifeng/tools/java/jdk1.8.0_271/bin/java -Xmx50G -jar /public1/home/yifeng/yifeng/tools/anaconda3/envs/py3/share/picard-2.23.8-0/picard.jar SortSam I=/public1/home/Zexian/turtle_proj/19.recombination_rate/01.bowtie/&quot;$line&quot; O=/public1/home/Zexian/turtle_proj/19.recombination_rate/01.bowtie/&quot;$line.finalsort.bam&quot; SORT_ORDER=coordinate &amp;&quot; &gt;&gt; resort.sh;done#ulimit -n 65535 &amp;&amp; remember to set wait for each 5line in case memory out of range./resort.sh#mark dupls *.finalsort.bam | xargs -n 1 | while read line ; do echo &quot;/public1/home/yifeng/yifeng/tools/java/jdk1.8.0_271/bin/java -Xmx50G -jar /public1/home/yifeng/yifeng/tools/anaconda3/envs/py3/share/picard-2.23.8-0/picard.jar MarkDuplicates I=/public1/home/Zexian/turtle_proj/19.recombination_rate/01.bowtie/&quot;$line&quot; O=/public1/home/Zexian/turtle_proj/19.recombination_rate/01.bowtie/&quot;$line.dup.bam&quot; METRICS_FILE=/public1/home/Zexian/turtle_proj/19.recombination_rate/01.bowtie/&quot;$line.metrics&quot; MAX_FILE_HANDLES=65535&quot; ;done &gt;&gt; markdup.sh#renamels *.dup.bam |xargs -n1 | while read line ;do echo &quot;mv &quot;$line &gt;&gt; log1 ;donels *.dup.bam |xargs -n1 | sed &#x27;s/.bam.fai.*.dup/.dup/g&#x27; &gt; log2paste log1 log2 | awk &#x27;&#123;print$0&quot; &amp;&quot;&#125;&#x27; &gt;log3./log3 &amp;&amp; rm log*#samtools indexls *.dup.bam |xargs -n 1| while read line ;do echo &quot;samtools index &quot;$line&quot; &amp;&quot; &gt;&gt; bamindex.sh ;done./bamindex.sh#get dict file of ref genome/public1/home/yifeng/yifeng/tools/java/jdk1.8.0_271/bin/java -Xmx2G -jar /public1/home/yifeng/yifeng/tools/anaconda3/envs/py3/share/picard-2.23.8-0/picard.jar CreateSequenceDictionary R=turtle.zjuv1.fa O=/public1/home/Zexian/turtle_proj/19.recombination_rate/01.bowtie/turtle.zjuv1.dict#generate gvcf file round1ls *.dup.bam | xargs -n 1 | while read line ; do echo &quot;/public1/home/yifeng/yifeng/tools/java/jdk1.8.0_271/bin/java -jar /public1/home/yifeng/yifeng/tools/anaconda3/envs/py3/opt/gatk-3.8/GenomeAnalysisTK.jar -T HaplotypeCaller -R /public1/home/Zexian/turtle_proj/19.recombination_rate/01.bowtie/turtle.zjuv1.fa -I /public1/home/Zexian/turtle_proj/19.recombination_rate/01.bowtie/&quot;$line&quot; -ERC GVCF -stand_call_conf 30 -ploidy 2 -o /public1/home/Zexian/turtle_proj/19.recombination_rate/01.bowtie/&quot;$line.vcf.rd1&quot; -variant_index_type LINEAR -variant_index_parameter 128000 &amp;&quot; &gt;&gt; vcfround1.sh ;done./vcfround1.sh#rename samples in gvcfls *.rd1 | xargs -n1 | while read line ;do echo &quot;/public1/home/yifeng/yifeng/tools/java/jdk1.8.0_271/bin/java -jar /public1/home/yifeng/yifeng/tools/anaconda3/envs/py3/share/picard-2.23.8-0/picard.jar RenameSampleInVcf I=&quot;$line&quot; O=&quot;$(basename $line .vcf.rd1).rename.vcf&quot; NEW_SAMPLE_NAME=&quot;$(basename $line .vcf.rd1)&quot; &amp;&quot; ;done | awk &#x27;NR%5==0&#123;print$0&quot;\\nwait&quot;&#125;NR%5!=0&#123;print$0&#125;&#x27;&gt; rename.sh ./rename.sh#genotypels *.rename.vcf |xargs -n1 | while read line ;do echo &quot; --variant &quot;$line ;done |xargs | while read line ;do echo &quot;/public1/home/yifeng/yifeng/tools/java/jdk1.8.0_271/bin/java -jar /public1/home/yifeng/yifeng/tools/anaconda3/envs/py3/opt/gatk-3.8/GenomeAnalysisTK.jar -T GenotypeGVCFs -R /public1/home/Zexian/turtle_proj/19.recombination_rate/01.bowtie/turtle.zjuv1.fa &quot;$line &quot;-o combine.output.vcf&quot; &gt;&gt; genotype.sh;done ./genotype.sh#filter snps/public1/home/yifeng/yifeng/tools/java/jdk1.8.0_271/bin/java -jar /public1/home/yifeng/yifeng/tools/anaconda3/envs/py3/opt/gatk-3.8/GenomeAnalysisTK.jar -T VariantFiltration -R /public1/home/Zexian/turtle_proj/19.recombination_rate/01.bowtie/turtle.zjuv1.fa --variant combine.output.vcf --clusterSize 4 --clusterWindowSize 10 --filterName &quot;lowMQRankSum&quot; --filterExpression &quot;MQRankSum &lt; -12.5&quot; --filterName &quot;highFS&quot; --filterExpression &quot;FS &gt; 60.0&quot; --filterName &quot;lowReadPosRankSum&quot; --filterExpression &quot;ReadPosRankSum &lt; -8.0&quot; --filterName &quot;lowMQ&quot; --filterExpression &quot;MQ &lt; 30.0&quot; --filterName &quot;lowQD&quot; --filterExpression &quot;QD &lt; 2.0&quot; --out combine.filter.snp.vcf --genotypeFilterName &quot;lowDP&quot; --genotypeFilterExpression &quot;DP &lt; 8.0&quot; &gt; filter_snp.errawk &#x27;$7==&quot;PASS&quot;||$1~&quot;#&quot;&#123;print&#125;&#x27; combine.filter.snp.vcf &gt; combine.filter.snp.final.vcf byLongxin 123456789101112131415ref=Mhap1refFa=ref/$&#123;ref&#125;.fastasample=malesamtools faidx $refFagatk CreateSequenceDictionary -R=$refFa -O=ChrAsm.dictgatk MarkDuplicates -I=$sample.$ref.sorted.bam -O=$sample.$ref.dedup.bam -M=$sample.$ref.msamtools index $sample.$ref.dedup.bamgatk AddOrReplaceReadGroups -I=$sample.$ref.dedup.bam -O=$sample.$ref.dedup.bam.rg.bam RGID=4$sample RGLB=lib$sample RGPU=unit1 RGSM=$sample RGPL=illuminasamtools index $sample.$ref.dedup.bam.rg.bam#java -Xmx83g -jar GenomeAnalysisTK.jar -T HaplotypeCaller -R $refFa -I $sample.$ref.dedup.bam.rg.bam --emitRefConfidence GVCF -o $sample.$ref.dedup.bam.rg.bam.g.vcf.gz -nct 12gatk --java-options &quot;-Xmx83G&quot; HaplotypeCaller -R $refFa -I $sample.$ref.dedup.bam.rg.bam --emitRefConfidence GVCF -o $sample.$ref.dedup.bam.rg.bam.g.vcf.gz -nct 12 genotyping 123456789101112131415ref=/public/home/fjnu_edu_hz/qianwei/wa/rawRef/wa_Male.hap1.fasta#01.CombineGVCFsgatk CombineGVCFs \\-R $ref \\--variant ./$&#123;sample1&#125;/$&#123;sample1&#125;.raw.snps.indels.g.vcf \\--variant ./$&#123;sample2&#125;/$&#123;sample2&#125;.raw.snps.indels.g.vcf \\--variant ./$&#123;sample3&#125;/$&#123;sample3&#125;.raw.snps.indels.g.vcf \\-O combined.raw.g.vcf.gz#02.genotypegatk --java-options &quot;-Xmx150G&quot; GenotypeGVCFs -R $ref -V combined.raw.g.vcf.gz -O All.raw.vcf.gz#03.filtergatk --java-options &quot;-Xmx150G&quot; SelectVariants -R $ref -V All.raw.vcf.gz -selectType SNP -O ref.snp.vcfgatk --java-options &quot;-Xmx150G&quot; VariantFiltration -R $ref -V ref.snp.vcf --filte-expression &quot; QD &lt; 2.0 || FS &gt; 60.0 || MQRankSum &lt; -12.5 || RedPosRankSum &lt; -8.0 || SOR &gt; 3.0 || MQ &lt; 40.0 &quot; --filter-name &quot;my_snp_filter&quot; -O ref.snp.filter.vcfgatk --java-options &quot;-Xmx150G&quot; SelectVariants -R $ref -V ref.snp.filter.vcf --exclude-filtered -O ref.snp.final.vcf.gz imputation and phasingfor i in {1..13}dovcftools –vcf ref.snp.final.vcf –chr Chr${i}_hap1 –maf 0.05 –recode –recode-INFO-all –out chr${i} java -Xmx100G -jar &#x2F;public&#x2F;home&#x2F;fjnu_edu_hz&#x2F;qianwei&#x2F;biosoft&#x2F;beagle.22Jul22.46e.jar gt&#x3D;chr${i}.recode.vcf out&#x3D;chr${i}_snp.IM nthreads&#x3D;4 gunzip chr${i}_snp.IM.vcf.gz awk ‘$1&#x2F;#&#x2F; || $5!&#x2F;,&#x2F;‘ chr${i}_snp.IM.vcf &gt; chr${i}_snp.IM.bi.vcf shapeit -V chr${i}_snp.IM.bi.vcf –window 0.5 -O chr${i}_snp.IM.Ph –thread 4 done for i in {1..13}; do cat chr${i}_snp.IM.Ph.haps &gt;&gt;snp.haps; done convert formatperl &#x2F;public&#x2F;home&#x2F;fjnu_edu_hz&#x2F;qianwei&#x2F;biosoft&#x2F;getsnpplink.pl snp.sample snp.haps snp.map snp.pedplink –file snp –out snp –make-bed –allow-extra-chr –allow-no-sex generate tped&#x2F;tfamplink –bfile snp –chr-set 13 –allow-extra-chr –allow-no-sex –recode 12 transpose –output-missing-genotype 0 –out snpplink –bfile snp –chr-set 13 –allow-extra-chr –pca –out snp generate phenotype fileawk ‘{print $1,$2,$6}’ snp.tfam &gt; snp.pheno #run emmax and use snp.hBN as final result.&#x2F;public&#x2F;home&#x2F;fjnu_edu_hz&#x2F;qianwei&#x2F;biosoft&#x2F;emmax&#x2F;emmax-kin-intel64 -v -h -s -d 10 snp&#x2F;public&#x2F;home&#x2F;fjnu_edu_hz&#x2F;qianwei&#x2F;biosoft&#x2F;emmax&#x2F;emmax-kin-intel64 -v -h -d 10 snp&#x2F;public&#x2F;home&#x2F;fjnu_edu_hz&#x2F;qianwei&#x2F;biosoft&#x2F;emmax&#x2F;emmax-intel64 -v -d 10 -t snp -p snp.pheno -k snp.hIBS.kinf -o snp.hIBS&#x2F;public&#x2F;home&#x2F;fjnu_edu_hz&#x2F;qianwei&#x2F;biosoft&#x2F;emmax&#x2F;emmax-intel64 -v -d 10 -t snp -p snp.pheno -k snp.hBN.kinf -o snp.hBN","tags":[],"categories":[{"name":"pipeline","slug":"pipeline","permalink":"https://sqwwww.github.io/categories/pipeline/"}]},{"title":"StardewValley","date":"2022-07-16T07:54:51.000Z","path":"wiki/game/StardewValley/","text":"小桶和罐头瓶 参考资料","tags":[],"categories":[{"name":"game","slug":"game","permalink":"https://sqwwww.github.io/categories/game/"}]},{"title":"stringtie使用","date":"2022-07-16T02:40:55.000Z","path":"wiki/biosoft/stringtie使用/","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869$stringtie -hStringTie v2.1.5 usage:stringtie &lt;in.bam ..&gt; [-G &lt;guide_gff&gt;] [-l &lt;prefix&gt;] [-o &lt;out.gtf&gt;] [-p &lt;cpus&gt;] [-v] [-a &lt;min_anchor_len&gt;] [-m &lt;min_len&gt;] [-j &lt;min_anchor_cov&gt;] [-f &lt;min_iso&gt;] [-c &lt;min_bundle_cov&gt;] [-g &lt;bdist&gt;] [-u] [-L] [-e] [--viral] [-E &lt;err_margin&gt;] [--ptf &lt;f_tab&gt;] [-x &lt;seqid,..&gt;] [-A &lt;gene_abund.out&gt;] [-h] &#123;-B|-b &lt;dir_path&gt;&#125;Assemble RNA-Seq alignments into potential transcripts.Options: --version : print just the version at stdout and exit --conservative : conservative transcript assembly, same as -t -c 1.5 -f 0.05 --rf : assume stranded library fr-firststrand --fr : assume stranded library fr-secondstrand -G reference annotation to use for guiding the assembly process (GTF/GFF3) --ptf : load point-features from a given 4 column feature file &lt;f_tab&gt; -o output path/file name for the assembled transcripts GTF (default: stdout) -l name prefix for output transcripts (default: STRG) -f minimum isoform fraction (default: 0.01) -L long reads processing; also enforces -s 1.5 -g 0 (default:false) -R if long reads are provided, just clean and collapse the reads but do not assemble -m minimum assembled transcript length (default: 200) -a minimum anchor length for junctions (default: 10) -j minimum junction coverage (default: 1) -t disable trimming of predicted transcripts based on coverage (default: coverage trimming is enabled) -c minimum reads per bp coverage to consider for multi-exon transcript (default: 1) -s minimum reads per bp coverage to consider for single-exon transcript (default: 4.75) -v verbose (log bundle processing details) -g maximum gap allowed between read mappings (default: 50) -M fraction of bundle allowed to be covered by multi-hit reads (default:1) -p number of threads (CPUs) to use (default: 1) -A gene abundance estimation output file -E define window around possibly erroneous splice sites from long reads to look out for correct splice sites (default: 25) -B enable output of Ballgown table files which will be created in the same directory as the output GTF (requires -G, -o recommended) -b enable output of Ballgown table files but these files will be created under the directory path given as &lt;dir_path&gt; -e only estimate the abundance of given reference transcripts (requires -G) --viral : only relevant for long reads from viral data where splice sites do not follow consensus (default:false) -x do not assemble any transcripts on the given reference sequence(s) -u no multi-mapping correction (default: correction enabled) -h print this usage message and exitTranscript merge usage mode: stringtie --merge [Options] &#123; gtf_list | strg1.gtf ...&#125;With this option StringTie will assemble transcripts from multipleinput files generating a unified non-redundant set of isoforms. In this modethe following options are available: -G &lt;guide_gff&gt; reference annotation to include in the merging (GTF/GFF3) -o &lt;out_gtf&gt; output file name for the merged transcripts GTF (default: stdout) -m &lt;min_len&gt; minimum input transcript length to include in the merge (default: 50) -c &lt;min_cov&gt; minimum input transcript coverage to include in the merge (default: 0) -F &lt;min_fpkm&gt; minimum input transcript FPKM to include in the merge (default: 1.0) -T &lt;min_tpm&gt; minimum input transcript TPM to include in the merge (default: 1.0) -f &lt;min_iso&gt; minimum isoform fraction (default: 0.01) -g &lt;gap_len&gt; gap between transcripts to merge together (default: 250) -i keep merged transcripts with retained introns; by default these are not kept unless there is strong evidence for them -l &lt;label&gt; name prefix for output transcripts (default: MSTRG) The generic command line for the default usage has this format:: 1stringtie [-o &lt;output.gtf&gt;] [other_options] &lt;read_alignments.bam&gt; StringTie takes as input a SAM, BAM or CRAM file sorted by coordinate (genomic location).samtools sort -o alnst.sorted.bam alns.sam A reference annotation file in GTF or GFF3 format can be provided to StringTie using the -G option which can be used as ‘guides’ for the assembly process and help improve the transcript structure recovery for those transcripts. Expression estimation mode (-e),我该用这个模式，只做定量When the -e option is used, the reference annotation file -G is a required input and StringTie will not attempt to assemble the input read alignments but instead it will only estimate the expression levels of the “reference” transcripts provided in the -G file. With this option, no “novel” transcript assemblies (isoforms) will be produced, and read alignments not overlapping any of the given reference transcripts will be ignored, which may provide a considerable speed boost when the given set of reference transcripts is limited to a set of target genes for example. for each RNA-Seq sample, map the reads to the genome with HISAT2 using the –dta option. It is highly recommended to use the reference annotation information when mapping the reads, which can be either embedded in the genome index (built with the –ss and –exon options, see HISAT2 manual), or provided separately at run time (using the –known-splicesite-infile option of HISAT2). The SAM output of each HISAT2 run must be sorted and converted to BAM using samtools as explained above. 参考网页 ：http://ccb.jhu.edu/software/stringtie/index.shtml?t=manual hisat2_index&#x3D;&#x2F;public2&#x2F;home&#x2F;qianwei&#x2F;project&#x2F;seahorse&#x2F;02.ref&#x2F;hisat2Index&#x2F;Hagff&#x3D;&#x2F;public2&#x2F;home&#x2F;qianwei&#x2F;project&#x2F;seahorse&#x2F;02.ref&#x2F;Ha.gffthreads&#x3D;15cat fq.list| while read id; doarr&#x3D;($id)fq1&#x3D;${arr[0]}fq2&#x3D;${arr[1]} hisat2 -p $threads –dta -x $hisat2_index -1 $fq1 -2 $fq2 -S ${sample}.samgrep -P ‘@|NH:i:1\\b’ ${sample}.sam | grep -v “ZS:i” &gt; ${sample}.uniq.samsamtools view -@ 4 -bS ${sample}.uniq.sam | samtools sort -@ 4 -m 3g -o ${sample}.uniq.bam -stringtie -p $threads -G ${gff} -B -e -l ${sample} -o ${sample}.gtf ${sample}.uniq.bam HISAT2 version 2.2.1 by Daehwan Kim (&#105;&#110;&#x66;&#x70;&#104;&#105;&#108;&#x6f;&#64;&#x67;&#x6d;&#x61;&#105;&#108;&#46;&#99;&#111;&#x6d;, www.ccb.jhu.edu/people/infphilo)Usage: hisat2 [options]* -x {-1 -2 | -U } [-S ] Index filename prefix (minus trailing .X.ht2). Files with #1 mates, paired with files in . Could be gzip’ed (extension: .gz) or bzip2’ed (extension: .bz2). Files with #2 mates, paired with files in . Could be gzip’ed (extension: .gz) or bzip2’ed (extension: .bz2). Files with unpaired reads. Could be gzip’ed (extension: .gz) or bzip2’ed (extension: .bz2). File for SAM output (default: stdout) , , can be comma-separated lists (no whitespace) and can be specified many times. E.g. ‘-U file1.fq,file2.fq -U file3.fq’. Options (defaults in parentheses): Input: -q query input files are FASTQ .fq&#x2F;.fastq (default) –qseq query input files are in Illumina’s qseq format -f query input files are (multi-)FASTA .fa&#x2F;.mfa -r query input files are raw one-sequence-per-line -c , , are sequences themselves, not files -s&#x2F;–skip skip the first reads&#x2F;pairs in the input (none) -u&#x2F;–upto stop after first reads&#x2F;pairs (no limit) -5&#x2F;–trim5 trim bases from 5’&#x2F;left end of reads (0) -3&#x2F;–trim3 trim bases from 3’&#x2F;right end of reads (0) –phred33 qualities are Phred+33 (default) –phred64 qualities are Phred+64 –int-quals qualities encoded as space-delimited integers Presets: Same as: –fast –no-repeat-index –sensitive –bowtie2-dp 1 -k 30 –score-min L,0,-0.5 –very-sensitive –bowtie2-dp 2 -k 50 –score-min L,0,-1 Alignment: –bowtie2-dp use Bowtie2’s dynamic programming alignment algorithm (0) - 0: no dynamic programming, 1: conditional dynamic programming, and 2: unconditional dynamic programming (slowest) –n-ceil func for max # non-A&#x2F;C&#x2F;G&#x2F;Ts permitted in aln (L,0,0.15) –ignore-quals treat all quality values as 30 on Phred scale (off) –nofw do not align forward (original) version of read (off) –norc do not align reverse-complement version of read (off) –no-repeat-index do not use repeat index Spliced Alignment: –pen-cansplice penalty for a canonical splice site (0) –pen-noncansplice penalty for a non-canonical splice site (12) –pen-canintronlen penalty for long introns (G,-8,1) with canonical splice sites –pen-noncanintronlen penalty for long introns (G,-8,1) with noncanonical splice sites –min-intronlen minimum intron length (20) –max-intronlen maximum intron length (500000) –known-splicesite-infile provide a list of known splice sites –novel-splicesite-outfile report a list of splice sites –novel-splicesite-infile provide a list of novel splice sites –no-temp-splicesite disable the use of splice sites found –no-spliced-alignment disable spliced alignment –rna-strandness specify strand-specific information (unstranded) –tmo reports only those alignments within known transcriptome –dta reports alignments tailored for transcript assemblers –dta-cufflinks reports alignments tailored specifically for cufflinks –avoid-pseudogene tries to avoid aligning reads to pseudogenes (experimental option) –no-templatelen-adjustment disables template length adjustment for RNA-seq reads Scoring: –mp , max and min penalties for mismatch; lower qual &#x3D; lower penalty &lt;6,2&gt; –sp , max and min penalties for soft-clipping; lower qual &#x3D; lower penalty &lt;2,1&gt; –no-softclip no soft-clipping –np penalty for non-A&#x2F;C&#x2F;G&#x2F;Ts in read&#x2F;ref (1) –rdg , read gap open, extend penalties (5,3) –rfg , reference gap open, extend penalties (5,3) –score-min min acceptable alignment score w&#x2F;r&#x2F;t read length (L,0.0,-0.2) Reporting: -k It searches for at most distinct, primary alignments for each read. Primary alignments mean alignments whose alignment score is equal to or higher than any other alignments. The search terminates when it cannot find more distinct valid alignments, or when it finds , whichever happens first. The alignment score for a paired-end alignment equals the sum of the alignment scores of the individual mates. Each reported read or pair alignment beyond the first has the SAM ‘secondary’ bit (which equals 256) set in its FLAGS field. For reads that have more than distinct, valid alignments, hisat2 does not guarantee that the alignments reported are the best possible in terms of alignment score. Default: 5 (linear index) or 10 (graph index). Note: HISAT2 is not designed with large values for -k in mind, and when aligning reads to long, repetitive genomes, large -k could make alignment much slower. –max-seeds HISAT2, like other aligners, uses seed-and-extend approaches. HISAT2 tries to extend seeds to full-length alignments. In HISAT2, –max-seeds is used to control the maximum number of seeds that will be extended. For DNA-read alignment (–no-spliced-alignment), HISAT2 extends up to these many seeds and skips the rest of the seeds. For RNA-read alignment, HISAT2 skips extending seeds and reports no alignments if the number of seeds is larger than the number specified with the option, to be compatible with previous versions of HISAT2. Large values for –max-seeds may improve alignment sensitivity, but HISAT2 is not designed with large values for –max-seeds in mind, and when aligning reads to long, repetitive genomes, large –max-seeds could make alignment much slower. The default value is the maximum of 5 and the value that comes with -k times 2. -a&#x2F;–all HISAT2 reports all alignments it can find. Using the option is equivalent to using both –max-seeds and -k with the maximum value that a 64-bit signed integer can represent (9,223,372,036,854,775,807). –repeat report alignments to repeat sequences directly Paired-end: -I&#x2F;–minins minimum fragment length (0), only valid with –no-spliced-alignment -X&#x2F;–maxins maximum fragment length (500), only valid with –no-spliced-alignment –fr&#x2F;–rf&#x2F;–ff -1, -2 mates align fw&#x2F;rev, rev&#x2F;fw, fw&#x2F;fw (–fr) –no-mixed suppress unpaired alignments for paired reads –no-discordant suppress discordant alignments for paired reads Output: -t&#x2F;–time print wall-clock time taken by search phases –un write unpaired reads that didn’t align to –al write unpaired reads that aligned at least once to –un-conc write pairs that didn’t align concordantly to –al-conc write pairs that aligned concordantly at least once to (Note: for –un, –al, –un-conc, or –al-conc, add ‘-gz’ to the option name, e.g. –un-gz , to gzip compress output, or add ‘-bz2’ to bzip2 compress output.) –summary-file print alignment summary to this file. –new-summary print alignment summary in a new style, which is more machine-friendly. –quiet print nothing to stderr except serious errors –met-file send metrics to file at (off) –met-stderr send metrics to stderr (off) –met report internal counters &amp; metrics every secs (1) –no-head suppress header lines, i.e. lines starting with @ –no-sq suppress @SQ header lines –rg-id set read group id, reflected in @RG line and RG:Z: opt field –rg add (“lab:value”) to @RG line of SAM header. Note: @RG line only printed when –rg-id is set. –omit-sec-seq put ‘*’ in SEQ and QUAL fields for secondary alignments. Performance: -o&#x2F;–offrate override offrate of index; must be &gt;&#x3D; index’s offrate -p&#x2F;–threads number of alignment threads to launch (1) –reorder force SAM output order to match order of input reads –mm use memory-mapped I&#x2F;O for index; many ‘hisat2’s can share Other: –qc-filter filter out reads that are bad according to QSEQ filter –seed seed for random number generator (0) –non-deterministic seed rand. gen. arbitrarily instead of using read attributes –remove-chrname remove ‘chr’ from reference names in alignment –add-chrname add ‘chr’ to reference names in alignment –version print version information and quit -h&#x2F;–help print this usage message $hisat2-buildNo input sequence or sequence file specified!HISAT2 version 2.2.1 by Daehwan Kim (&#x69;&#110;&#x66;&#112;&#x68;&#105;&#108;&#111;&#x40;&#x67;&#109;&#97;&#x69;&#x6c;&#x2e;&#x63;&#x6f;&#x6d;, http://www.ccb.jhu.edu/people/infphilo)Usage: hisat2-build [options]* reference_in comma-separated list of files with ref sequences hisat2_index_base write ht2 data to files with this dir&#x2F;basenameOptions: -c reference sequences given on cmd line (as ) –large-index force generated index to be ‘large’, even if ref has fewer than 4 billion nucleotides -a&#x2F;–noauto disable automatic -p&#x2F;–bmax&#x2F;–dcv memory-fitting -p number of threads –bmax max bucket sz for blockwise suffix-array builder –bmaxdivn max bucket sz as divisor of ref len (default: 4) –dcv diff-cover period for blockwise (default: 1024) –nodc disable diff-cover (algorithm becomes quadratic) -r&#x2F;–noref don’t build .3&#x2F;.4.ht2 (packed reference) portion -3&#x2F;–justref just build .3&#x2F;.4.ht2 (packed reference) portion -o&#x2F;–offrate SA is sampled every 2^offRate BWT chars (default: 5) -t&#x2F;–ftabchars # of chars consumed in initial lookup (default: 10) –localoffrate SA (local) is sampled every 2^offRate BWT chars (default: 3) –localftabchars # of chars consumed in initial lookup in a local index (default: 6) –snp SNP file name –haplotype haplotype file name –ss Splice site file name –exon Exon file name –repeat-ref Repeat reference file name –repeat-info Repeat information file name –repeat-snp Repeat snp file name –repeat-haplotype Repeat haplotype file name –seed seed for random number generator -q&#x2F;–quiet disable verbose output (for debugging) -h&#x2F;–help print detailed description of tool and its options –usage print this usage message –version print version information and quit","tags":[],"categories":[{"name":"biosoft","slug":"biosoft","permalink":"https://sqwwww.github.io/categories/biosoft/"}]},{"title":"hisat2 rsem 连用","date":"2022-07-16T02:19:15.000Z","path":"wiki/biosoft/hisat2-rsem-连用/","text":"尝试使用rsem定量hisat2的比对结果，失败了 $rsem-calculate-expression –paired-end –alignments Ha5_Fb2.uniq.bam &#x2F;public2&#x2F;home&#x2F;qianwei&#x2F;project&#x2F;seahorse&#x2F;02.ref&#x2F;RsemIndex&#x2F;Ha_Rsem Ha5_Fb2rsem-parse-alignments &#x2F;public2&#x2F;home&#x2F;qianwei&#x2F;project&#x2F;seahorse&#x2F;02.ref&#x2F;RsemIndex&#x2F;Ha_Rsem Ha5_Fb2.temp&#x2F;Ha5_Fb2 Ha5_Fb2.stat&#x2F;Ha5_Fb2 Ha5_Fb2.uniq.bam 3 -tag XMWarning: The SAM&#x2F;BAM file declares less reference sequences (168) than RSEM knows (27642)! Please make sure that you aligned your reads against transcript sequences instead of genome.RSEM can not recognize reference sequence name Chr1!“rsem-parse-alignments &#x2F;public2&#x2F;home&#x2F;qianwei&#x2F;project&#x2F;seahorse&#x2F;02.ref&#x2F;RsemIndex&#x2F;Ha_Rsem Ha5_Fb2.temp&#x2F;Ha5_Fb2 Ha5_Fb2.stat&#x2F;Ha5_Fb2 Ha5_Fb2.uniq.bam 3 -tag XM” failed! Plase check if you provide correct parameters&#x2F;options for the pipeline! 原因分析：表面上这个报错是说 hisat2的bam文件跟 Rsem 的索引不兼容。实际上 rsem 不支持 gapped alignment的定量，hisat2在比对过程中使用的就是 gapped alignment，所以两个软件本质上就是不兼容的，不能连用。","tags":[],"categories":[{"name":"biosoft","slug":"biosoft","permalink":"https://sqwwww.github.io/categories/biosoft/"}]},{"title":"hexo/vsCode使用技巧","date":"2022-07-15T07:39:40.000Z","path":"wiki/tmp/hexo-vsCode使用技巧/","text":"ctrl+shift+L 选中编辑代码中相同的内容按住Ctrl + Alt，再按键盘上的上或下键，可以使一列上出现多个光标","tags":[],"categories":[{"name":"tmp","slug":"tmp","permalink":"https://sqwwww.github.io/categories/tmp/"}]},{"title":"hexo/hexo_push_error","date":"2022-07-15T07:31:49.000Z","path":"wiki/tmp/hexo-push-error/","text":"hexo 向 git 上推送时，报错如下 kex_exchange_identification: read: Connection reset by peerConnection reset by 20.205.243.166 port 22fatal: Could not read from remote repository. Please make sure you have the correct access rightsand the repository exists.\u001b[41mFATAL\u001b[49m { err: Error: Spawn failed at ChildProcess. &gt;(D:\\gitpages\\node_modules\\hexo-util\\lib\\spawn.js:51:21) at ChildProcess.emit (node:events:527:28) at ChildProcess.cp.emit &gt;(D:\\gitpages\\node_modules\\cross-spawn\\lib\\enoent.js:34:29) at Process.ChildProcess._handle.onexit (node:internal&#x2F;&gt;child_process:291:12) { code: 128 }} Something’s wrong. Maybe you can find the solution here: %s \u001b[4mhttps:&#x2F;&#x2F;&gt;hexo.io&#x2F;docs&#x2F;troubleshooting.html\u001b[24m 分析：首先怀疑是本地不能正常连接到 github 所导致,测试连接是否正常 12D:\\gitpages&gt;ssh -T git@github.comkex_exchange_identification: read: Connection reset 确实是连接出了问题，尝试解决方法如下： 1234567891011121314D:\\gitpages&gt;ssh-keygen -R 20.205.243.166# Host 20.205.243.166 found: line 1C:\\Users\\sqw/.ssh/known_hosts updated.Original contents retained as C:\\Users\\sqw/.ssh/known_hosts.old#这里是重新生成了known_host文件D:\\gitpages&gt;ssh -T git@github.comThe authenticity of host &#x27;github.com (20.205.243.166)&#x27; can&#x27;t be established.ECDSA key fingerprint is SHA256:p2QAMXNIC1TJYWeIOttrVc98/R1BUFWu3/LiyKgUfQM.Are you sure you want to continue connecting (yes/no/[fingerprint])? yPlease type &#x27;yes&#x27;, &#x27;no&#x27; or the fingerprint: yesWarning: Permanently added &#x27;github.com,20.205.243.166&#x27; (ECDSA) to the list of known hosts.Hi sqwwww! You&#x27;ve successfully authenticated, but GitHub does not provide shell access.#本地重新把github的指纹加进known host文件里。 接下来执行 123hexo cleanhexo ghexo d 成功推送 gitpages默认branch是main，但我的主页设置在master，需要把默认branch从main改成master参照这篇 https://blog.csdn.net/xuchaoxin1375/article/details/111414527github允许每个仓库的default branch 可以单独设置","tags":[{"name":"bug, hexo, push","slug":"bug-hexo-push","permalink":"https://sqwwww.github.io/tags/bug-hexo-push/"}],"categories":[{"name":"tmp","slug":"tmp","permalink":"https://sqwwww.github.io/categories/tmp/"}]},{"title":"test","date":"2022-07-15T05:02:29.000Z","path":"wiki/biosoft/seqkit/","text":"seqkit seqkit subseq –bed Fhap1_dmrt1.name -o Fhap1_dmrt1.fasta ..&#x2F;hap_chro&#x2F;F_hap1.groups.asm.fasta","tags":[],"categories":[{"name":"biosoft","slug":"biosoft","permalink":"https://sqwwww.github.io/categories/biosoft/"}]},{"title":"表皮发育","date":"2022-07-15T05:02:29.000Z","path":"wiki/knowledge/表皮发育/","text":"haCTLI, haCTLII, haCTLIII在muscle，brain，ovary，kidney中不表达，在brood pouch中表达brood pouch可以被分成两部分，外表皮和dermis，假胎盘和内表皮。haCTLI和II在这两部分都有表达，VI只在后者（假胎盘和内表皮）有表达进一步的染色发现，haCTLII蛋白质同时存在于内表皮和外表皮中， haCTL VI 则特异定位于内表皮。对pouch entrance 的 haCTL II，VI的信号做了进一步研究，haCTLII与在pouch中的表达相同，在内表皮和外表皮中都有表达；对于haCTLVI，信号在entrance中部变弱，在靠近外表皮的地方则完全消失。 在比较早期的个体（early stage，我们的数据里是stage1，stage2）中，haCTLII依然可以在内外表皮都检测到，但haCTLL IV的信号在内外表皮中都没有检测到，说明haCTL VI在内表皮的合成是在pouch发育过程中逐渐开始的，stage1，2还没有合成，可能stage3和stage4逐渐开始合成 mitochondria-rich cells 在哪些物种里报道过，作用是什么，位置在哪里，随着发育怎么变化这些细胞跟鱼鳃中调节渗透压的细胞很像，在鳃中，这些细胞含有催乳素（prolactin）的受体，催乳素是鱼渗透压调节相关的主要激素，并在大多数动物的父母行为中发挥作用 This envelope (zona radiata,辐射带) in teleosts normally consists of two layers, a zona radiata interna（辐射带内层） and a zona radiata externa（辐射带）.","tags":[],"categories":[{"name":"knowledge","slug":"knowledge","permalink":"https://sqwwww.github.io/categories/knowledge/"}]},{"title":"SqwPersonal","date":"2022-07-15T04:49:53.000Z","path":"wiki/SqwPersonal/","text":"","tags":[],"categories":[]}],"categories":[{"name":"codeSkill","slug":"codeSkill","permalink":"https://sqwwww.github.io/categories/codeSkill/"},{"name":"knowledge","slug":"knowledge","permalink":"https://sqwwww.github.io/categories/knowledge/"},{"name":"biosoft","slug":"biosoft","permalink":"https://sqwwww.github.io/categories/biosoft/"},{"name":"pipeline","slug":"pipeline","permalink":"https://sqwwww.github.io/categories/pipeline/"},{"name":"error","slug":"biosoft/error","permalink":"https://sqwwww.github.io/categories/biosoft/error/"},{"name":"tmp","slug":"tmp","permalink":"https://sqwwww.github.io/categories/tmp/"},{"name":"game","slug":"game","permalink":"https://sqwwww.github.io/categories/game/"}],"tags":[{"name":"statistic, ANOVA, MANOVA","slug":"statistic-ANOVA-MANOVA","permalink":"https://sqwwww.github.io/tags/statistic-ANOVA-MANOVA/"},{"name":"集群","slug":"集群","permalink":"https://sqwwww.github.io/tags/%E9%9B%86%E7%BE%A4/"},{"name":"paperReading, teacher","slug":"paperReading-teacher","permalink":"https://sqwwww.github.io/tags/paperReading-teacher/"},{"name":"bug, hexo, push","slug":"bug-hexo-push","permalink":"https://sqwwww.github.io/tags/bug-hexo-push/"}]}